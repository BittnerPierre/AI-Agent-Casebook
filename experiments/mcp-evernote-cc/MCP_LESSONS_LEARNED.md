# MCP - Ce que vous devez savoir avant de vous lancer

> **Retours d'exp√©rience pratiques sur le d√©veloppement avec Model Context Protocol (MCP)**
>
> Document bas√© sur 3 impl√©mentations r√©elles :
> - **mcp-evernote-cc** : Chatbot Evernote avec Docker + stdio
> - **customer_onboarding** : Int√©gration HubSpot avec OAuth + Streamable HTTP
> - **agentic-research** : Serveur MCP custom pour DataPrep avec SSE

---

## üéØ Public Cible

Ce document s'adresse aux **Applied Engineers** qui :
- ‚úÖ Ont lu la documentation de base MCP (quickstart)
- ‚úÖ Ont vu les vid√©os d'introduction (deeplearning.ai)
- ‚úÖ Ont peut-√™tre branch√© 1-2 MCP dans Claude ou Cursor
- üéØ Veulent maintenant utiliser MCP dans leurs propres projets AI

**Objectif** : Partager les pi√®ges, patterns et le√ßons apprises au-del√† de la documentation officielle.

---

## üìö Les 3 Types de MCP - L'Essentiel

Le MCP expose 3 types de capacit√©s aux agents LLM :

### 1. **Prompts** (Templates)
Fournit des prompts pr√©-d√©finis et contextualis√©s aux agents.

**Cas d'usage** : Standardiser les interactions, templates de requ√™tes

### 2. **Resources** (Donn√©es)
Expose des ressources en lecture seule (fichiers, donn√©es, documentation).

**Cas d'usage** : Documentation, contexte statique, donn√©es de r√©f√©rence

### 3. **Tools** (Actions)
Expose des fonctions ex√©cutables par l'agent.

**Cas d'usage** : Actions, int√©grations API, transformations de donn√©es

> **Note pratique** : Dans nos 3 projets, on utilise principalement des **Tools** car ils permettent l'interactivit√© et les actions concr√®tes.

---

## üîß Les 2 Protocoles de Transport - Stdio vs SSE/HTTP

### **Stdio** (Standard Input/Output)

**Quand l'utiliser** :
- ‚úÖ Serveurs MCP locaux (Docker, processus local)
- ‚úÖ Desktop apps avec acc√®s terminal
- ‚úÖ D√©veloppement et debugging (logs directs)

**Limitations** :
- ‚ùå Ne fonctionne pas avec SaaS (ChatGPT, Le Chat, etc.)
- ‚ùå N√©cessite acc√®s processus local
- ‚ùå Complexe pour le d√©ploiement cloud

**Exemple (Evernote via Docker)** :
```python
from agents.mcp import MCPServerStdio

evernote_mcp_server = MCPServerStdio(
    name="EVERNOTE_MCP_SERVER",
    params={
        "command": "docker",
        "args": [
            "exec", "-i", "--tty=false",
            container_name,
            "sh", "-c", "node mcp-server.js 2>/dev/null"
        ],
    },
    cache_tools_list=True,
)
```

### **Streamable HTTP / SSE** (Server-Sent Events)

**Quand l'utiliser** :
- ‚úÖ Serveurs MCP distants (cloud, SaaS)
- ‚úÖ Int√©grations OAuth n√©cessaires
- ‚úÖ D√©ploiement web/production
- ‚úÖ Acc√®s depuis n'importe o√π (ChatGPT, agents cloud)

**Limitations** :
- ‚ùå Plus complexe √† configurer (auth, headers, URL)
- ‚ùå Latence r√©seau √† consid√©rer
- ‚ùå N√©cessite infrastructure d√©ploy√©e

**Exemple (HubSpot OAuth)** :
```python
from agents.mcp import MCPServerStreamableHttp

token = await oauth()

mcp_hubspot_server = MCPServerStreamableHttp(
    name="Streamable HTTP Python Server",
    params={
        "url": "https://mcp.hubspot.com",
        "headers": {"Authorization": f"Bearer {token['access_token']}"},
        "timeout": 10
    },
    cache_tools_list=True,
    max_retry_attempts=3,
)
```

### **Comparaison Pratique**

| Crit√®re | Stdio | Streamable HTTP/SSE |
|---------|-------|---------------------|
| **Latence** | Tr√®s faible (local) | D√©pend du r√©seau |
| **S√©curit√©** | Processus local (sandbox) | OAuth, HTTPS |
| **D√©ploiement** | Simple (local) | Infrastructure requise |
| **Debugging** | Facile (logs directs) | Plus complexe (r√©seau) |
| **SaaS Compatible** | ‚ùå Non | ‚úÖ Oui |
| **Production** | ‚ùå Limit√© | ‚úÖ Recommand√© |

---

## ‚ö†Ô∏è LE√áON #1 : Cycle de Vie du Client MCP

### Le Probl√®me : "Server not initialized"

**Erreur rencontr√©e** (commit d9294ac) :
```
‚ùå Error: Server not initialized
‚ùå MCP connection closed unexpectedly
```

### Cause Racine

Ne **JAMAIS** cr√©er un wrapper custom qui g√®re le cycle de vie du client MCP. Le client MCP doit √™tre g√©r√© via **async context manager**.

**Mauvais Pattern (√† √©viter)** :
```python
# ‚ùå NE PAS FAIRE √áA - Custom wrapper manuel
class CustomMCPClient:
    def __init__(self):
        self.client = None

    def connect(self):
        # Connection manuelle
        pass

    def disconnect(self):
        # Disconnection manuelle
        pass
```

**Bon Pattern** :
```python
# ‚úÖ BON - Utiliser MCPServerStdio natif avec context manager
from agents.mcp import MCPServerStdio

async with MCPServerStdio(...) as mcp_server:
    agent = Agent(
        name="My Agent",
        mcp_servers=[mcp_server],  # Agent d√©couvre automatiquement les tools
    )
    result = await Runner.run(agent, conversation)
```

### Le√ßons Cl√©s

1. **Ne pas r√©inventer la roue** : Utiliser `MCPServerStdio` ou `MCPServerStreamableHttp` natifs
2. **Context Manager obligatoire** : `async with mcp_server as server:` garantit le lifecycle
3. **Scope de session** : Cr√©er le serveur MCP au d√©but de la session, le r√©utiliser pour toutes les requ√™tes
4. **√âviter le multithreading** : Un client MCP par session, pas de partage entre threads

### √âvolution du Code (mcp-evernote-cc)

**Avant** (166 lignes de wrapper custom supprim√©es) :
```python
# ‚ùå ProperMCPClient custom avec gestion manuelle
class ProperMCPClient:
    async def initialize(self):
        # Gestion manuelle lifecycle
        pass
```

**Apr√®s** (architecture simplifi√©e) :
```python
# ‚úÖ MCPServerStdio natif + context manager
async with MCPServerStdio(...) as mcp_server:
    agent = _create_evernote_agent_with_mcp(mcp_server)
    result = await Runner.run(agent, conversation)
```

**B√©n√©fices** :
- üìâ -166 lignes de code custom
- üêõ Erreurs "Server not initialized" r√©solues
- üöÄ D√©couverte automatique des tools par l'agent
- üîÑ Meilleure gestion du cycle de vie

---

## ‚ö†Ô∏è LE√áON #2 : OAuth et Authentification Distante

### Le Challenge : HubSpot MCP avec OAuth

**Contexte** : Int√©grer le serveur MCP HubSpot n√©cessite :
1. OAuth 2.0 flow (authorization code)
2. Token refresh automatique
3. Persistance du token entre sessions

### Architecture OAuth Compl√®te

```mermaid
sequenceDiagram
    participant A as Agent
    participant M as MCP Client
    participant O as OAuth Manager
    participant B as Browser
    participant H as HubSpot OAuth
    participant S as Local Server

    A->>M: Besoin connexion MCP
    M->>O: get_token()
    O->>O: Check token valide?

    alt Token valide
        O-->>M: Return token
    else Token expir√©
        O->>H: Refresh token
        H-->>O: New token
        O-->>M: Return token
    else Pas de token
        O->>S: Start local server (port 3000)
        O->>B: Open browser
        B->>H: User login
        H->>S: Callback with code
        S->>O: Return code
        O->>H: Exchange code for token
        H-->>O: Access token + Refresh token
        O->>O: Save to .hubspot_token.json
        O->>S: Stop local server
        O-->>M: Return token
    end

    M->>M: Create MCPServerStreamableHttp
    M->>A: MCP server ready
```

### Impl√©mentation Compl√®te

**Fichier** : `experiments/customer_onboarding/my_agents/oauth.py` (286 lignes)

**Pattern Singleton + Thread-Safe** :
```python
class OAuthManager:
    def __init__(self):
        self._token: Optional[Dict[str, Any]] = None
        self._lock = asyncio.Lock()  # Thread-safety
        self._server: Optional[HTTPServer] = None

    async def get_token(self) -> Dict[str, Any]:
        async with self._lock:
            # 1. Load from file
            if self._token is None:
                self._token = self._load_token_from_file()

            # 2. Check validity (with 5min margin)
            if self._token and self._is_token_valid(self._token):
                return self._token

            # 3. Try refresh
            if self._token and self._token.get("refresh_token"):
                try:
                    self._token = await self._refresh_token(...)
                    return self._token
                except Exception:
                    pass

            # 4. New OAuth flow
            self._token = await self._do_oauth_flow()
            return self._token
```

### Flow OAuth D√©taill√©

**1. Local Callback Server** :
```python
async def _start_local_server(self) -> None:
    # Try ports 3000-3009 (fallback if occupied)
    for port in range(3000, 3010):
        try:
            self._server = HTTPServer(("localhost", port), OAuthHandler)
            self._server.auth_event = threading.Event()
            self._server_thread = threading.Thread(
                target=self._server.serve_forever,
                daemon=True
            )
            self._server_thread.start()
            return
        except OSError as e:
            continue
```

**2. Browser Flow** :
```python
async def _do_oauth_flow(self) -> Dict[str, Any]:
    oauth_session = OAuth2Session(
        client_id=CLIENT_ID,
        redirect_uri=REDIRECT_URI,
        scope=["crm.objects.contacts.read", "crm.objects.companies.read", ...]
    )

    authorization_url, state = oauth_session.authorization_url(
        AUTHORIZATION_BASE_URL
    )

    webbrowser.open(authorization_url)

    # Wait for callback (5min timeout)
    if not self._server.auth_event.wait(timeout=300):
        raise TimeoutError("OAuth callback timeout")

    # Exchange code for token
    token = oauth_session.fetch_token(
        TOKEN_URL,
        code=self._server.auth_code,
        client_secret=CLIENT_SECRET,
    )

    return token
```

**3. Token Persistence** :
```python
TOKEN_FILE = Path(".hubspot_token.json")

def _save_token_to_file(self, token: Dict[str, Any]) -> None:
    with open(TOKEN_FILE, 'w') as f:
        json.dump(token, f, indent=2)

def _is_token_valid(self, token: Dict[str, Any]) -> bool:
    expires_at = token.get("expires_at")
    margin = 5 * 60  # 5 minutes
    return time.time() < (expires_at - margin)
```

### Utilisation avec MCP

```python
async def run_onboarding_agent_with_mcp(conversation: list[dict[str, str]]):
    # 1. Get valid token (auto-refresh if needed)
    token = await oauth()

    # 2. Create MCP server with auth header
    mcp_hubspot_server = MCPServerStreamableHttp(
        name="Streamable HTTP Python Server",
        params={
            "url": "https://mcp.hubspot.com",
            "headers": {"Authorization": f"Bearer {token['access_token']}"},
            "timeout": 10
        },
        cache_tools_list=True,
        max_retry_attempts=3,
    )

    # 3. Use MCP server in agent context
    async with mcp_hubspot_server as server:
        customer_onboarding_agent = _create_agents_with_mcp(server)
        result = await Runner.run(customer_onboarding_agent, conversation)
        return result
```

### Le√ßons OAuth

1. **Singleton pattern** : Une seule instance d'OAuthManager pour √©viter les conflits
2. **Token refresh automatique** : V√©rifier validit√© avant chaque utilisation (marge 5min)
3. **Persistance fichier** : `.hubspot_token.json` pour r√©utiliser entre sessions
4. **Local server avec ports fallback** : Essayer 3000-3009 si occup√©
5. **Thread-safety** : `asyncio.Lock()` pour op√©rations concurrentes
6. **Timeout reasonable** : 5 minutes pour OAuth flow
7. **Cleanup server** : Toujours stopper le serveur local apr√®s callback

---

## ‚ö†Ô∏è LE√áON #3 : Cr√©er un Serveur MCP Custom

### Cas d'Usage : MCP DataPrep Server

**Objectif** : Serveur MCP custom pour g√©rer la pr√©paration de donn√©es et vector stores OpenAI.

**Architecture** :
```
Agent ‚Üí MCP DataPrep Server (SSE) ‚Üí Knowledge DB (JSON + Files)
                ‚Üì
        OpenAI Files API + Vector Store
```

### Impl√©mentation avec FastMCP

**Fichier** : `experiments/agentic-research/src/mcp/dataprep_server.py`

```python
from fastmcp import FastMCP

def create_dataprep_server() -> FastMCP:
    mcp = FastMCP(
        name="DataPrep MCP Server",
        instructions="""
        Serveur MCP pour la pr√©paration de donn√©es et gestion de vector stores.

        Outils disponibles:
        - download_and_store_url: T√©l√©charge et stocke une URL
        - upload_files_to_vectorstore: Upload vers OpenAI Vector Store
        - get_knowledge_entries: Liste les entr√©es de la base
        """,
    )

    # Tool 1: Download and Store
    @mcp.tool()
    def download_and_store_url_tool(url: str) -> str:
        """
        T√©l√©charge et stocke une URL dans le syst√®me local.

        Args:
            url: URL √† t√©l√©charger

        Returns:
            str: Nom du fichier local cr√©√© (.md)
        """
        config = get_config()
        return download_and_store_url(url, config)

    # Tool 2: Upload to Vector Store
    @mcp.tool()
    def upload_files_to_vectorstore_tool(
        inputs: list[str],
        vectorstore_name: str
    ) -> dict[str, Any]:
        """
        Upload des fichiers vers un vector store OpenAI.

        Args:
            inputs: Liste d'URLs ou noms de fichiers locaux
            vectorstore_name: Nom du vector store √† cr√©er

        Returns:
            Dict avec vectorstore_id et m√©triques
        """
        config = get_config()
        result = upload_files_to_vectorstore(inputs, config, vectorstore_name)
        return result.model_dump()

    # Tool 3: Get Knowledge Entries
    @mcp.tool()
    def get_knowledge_entries_tool() -> list[dict[str, Any]]:
        """
        Liste toutes les entr√©es de la base de connaissances.

        Returns:
            List[Dict]: Entr√©es avec url, filename, title, keywords
        """
        config = get_config()
        return get_knowledge_entries(config)

    return mcp

def start_server(host: str = "0.0.0.0", port: int = 8001):
    """D√©marre le serveur MCP dataprep."""
    server = create_dataprep_server()
    server.run(transport="sse", host=host, port=port)
```

### D√©marrage du Serveur

```bash
# D√©marrer le serveur MCP DataPrep
poetry run dataprep_server

# Le serveur sera accessible sur http://localhost:8001 avec transport SSE
```

### Backend : Knowledge Database Thread-Safe

**Probl√®me** : Acc√®s concurrent √† `knowledge_db.json` depuis plusieurs agents.

**Solution** : Portalocker + Pattern Read-Merge-Write atomique.

**Fichier** : `src/dataprep/knowledge_db.py`

```python
import portalocker
from contextlib import contextmanager

class KnowledgeDBManager:
    def __init__(self, db_path: Path):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)

    @contextmanager
    def _file_lock(self, mode='r+'):
        """Context manager pour verrouillage de fichier."""
        if not self.db_path.exists() and 'r' in mode:
            self._initialize_empty_db()

        with open(self.db_path, mode, encoding='utf-8') as f:
            try:
                portalocker.lock(f, portalocker.LOCK_EX)
                yield f
            finally:
                portalocker.unlock(f)

    def add_entry(self, entry: KnowledgeEntry) -> None:
        """Pattern read-merge-write thread-safe."""
        with self._file_lock('r+') as f:
            # READ
            f.seek(0)
            data = json.load(f)
            db = KnowledgeDatabase(**data)

            # MERGE
            db.add_entry(entry)

            # WRITE
            f.seek(0)
            f.truncate()
            f.write(db.model_dump_json(indent=2))
```

### Mod√®les de Donn√©es

**Fichier** : `src/dataprep/models.py`

```python
from pydantic import BaseModel, Field, HttpUrl
from datetime import datetime

class KnowledgeEntry(BaseModel):
    url: HttpUrl
    filename: str
    title: Optional[str] = None
    keywords: List[str] = Field(default_factory=list)
    summary: Optional[str] = None
    openai_file_id: Optional[str] = None  # Optimisation uploads
    created_at: datetime = Field(default_factory=datetime.now)
    last_uploaded_at: Optional[datetime] = None

class KnowledgeDatabase(BaseModel):
    entries: List[KnowledgeEntry] = Field(default_factory=list)
    version: str = Field(default="1.0")
    last_updated: datetime = Field(default_factory=datetime.now)

    def find_by_url(self, url: str) -> Optional[KnowledgeEntry]:
        for entry in self.entries:
            if str(entry.url) == url:
                return entry
        return None

    def find_by_name(self, filename: str) -> Optional[KnowledgeEntry]:
        for entry in self.entries:
            if entry.filename == filename:
                return entry
        return None
```

### Optimisation : R√©utilisation des Uploads OpenAI

**Probl√®me** : Re-upload des m√™mes fichiers √† chaque session ‚Üí co√ªt et temps.

**Solution** : Stocker `openai_file_id` dans knowledge_db.json.

```python
def upload_files_to_vectorstore(
    inputs: List[str],
    config,
    vectorstore_name: str
) -> UploadResult:
    files_to_attach = []
    upload_count = 0
    reuse_count = 0

    for entry, file_path in entries_to_process:
        if entry.openai_file_id:
            # ‚úÖ Fichier d√©j√† upload√©, r√©utiliser
            logger.info(f"‚ôªÔ∏è R√©utilisation: {entry.filename} -> {entry.openai_file_id}")
            files_to_attach.append((entry.openai_file_id, entry.filename))
            reuse_count += 1
        else:
            # üÜï Nouveau fichier, upload n√©cessaire
            file_upload_response = client.files.create(
                file=file,
                purpose='user_data'
            )
            file_id = file_upload_response.id

            # Mettre √† jour la base de connaissances
            db_manager.update_openai_file_id(entry.filename, file_id)
            upload_count += 1

    # Create vector store with 1 day expiration
    vector_store = client.vector_stores.create(
        name=vectorstore_name,
        expires_after=ExpiresAfter(anchor="last_active_at", days=1)
    )

    # Attach files (nouveaux + r√©utilis√©s)
    # ...

    return UploadResult(
        vectorstore_id=vector_store.id,
        total_files_requested=len(inputs),
        upload_count=upload_count,
        reuse_count=reuse_count,
        # ...
    )
```

**R√©sultat Mesur√©** :
- üìä Premier run : 6 fichiers ‚Üí 35 secondes (6 uploads)
- üöÄ Second run : 6 fichiers ‚Üí 12 secondes (0 upload, 6 r√©utilis√©s)
- ‚ö° **65% d'am√©lioration de performance**
- üí∞ **100% d'√©conomie sur uploads OpenAI**

### Le√ßons Serveur MCP Custom

1. **FastMCP** : Framework simple pour cr√©er des serveurs MCP en Python
2. **Transport SSE** : `server.run(transport="sse")` pour compatibilit√© cloud/SaaS
3. **Thread-safety** : Portalocker + pattern read-merge-write atomique obligatoire
4. **Optimisations** : Stocker les IDs OpenAI pour r√©utilisation
5. **Pydantic** : Sch√©mas stricts pour validation et s√©rialisation
6. **Context local** : Utiliser `get_config()` dans chaque tool pour isolation
7. **Logging structur√©** : M√©triques d√©taill√©es pour debugging et monitoring

---

## ‚ö†Ô∏è LE√áON #4 : Async et Dur√©e de Vie des Agents

### Le Pattern Async Correct

**Important** : Les agents OpenAI Agents SDK sont **async-first**.

**Mauvais Pattern** :
```python
# ‚ùå Ne fonctionne pas - bloque l'event loop
def run_agent(conversation):
    result = Runner.run(agent, conversation)  # ‚ùå Bloque
    return result
```

**Bon Pattern** :
```python
# ‚úÖ Async correct
async def run_agent(conversation):
    result = await Runner.run(agent, conversation)
    return result

# ‚úÖ Ou avec streaming
async def run_agent_streamed(conversation):
    streamed_result = Runner.run_streamed(agent, conversation)
    async for event in streamed_result.stream_events():
        # Process events
        pass
```

### Dur√©e de Vie : Session vs Requ√™te

**Pattern Recommand√©** : Cr√©er le serveur MCP au d√©but de la session, le r√©utiliser.

```python
# ‚úÖ BON - MCP server cr√©√© une fois par session
async def interactive_cli():
    # Initialize MCP server once
    container_name = os.getenv("CONTAINER_NAME", "...")
    mcp_server = _create_evernote_mcp_server(container_name)

    while True:
        user_input = input("You: ")

        # Reuse same mcp_server across queries
        response, history = await run_evernote_agent_interactive(
            mcp_server=mcp_server,
            user_input=user_input,
            conversation_history=history
        )

        print(f"Assistant: {response}")
```

**√âviter** :
```python
# ‚ùå MAUVAIS - Cr√©er un nouveau serveur MCP √† chaque requ√™te
async def run_agent(query):
    mcp_server = _create_mcp_server()  # ‚ùå Co√ªteux
    async with mcp_server as server:
        result = await Runner.run(agent, [{"role": "user", "content": query}])
    return result
```

### Gestion du Streaming

**Pattern √âl√©gant** pour afficher les tool calls avec spinners :

```python
from rich.live import Live
from rich.spinner import Spinner
from rich.console import Group

async def run_evernote_agent_interactive(mcp_server, user_input, conversation_history):
    live = Live(console=console, auto_refresh=True, transient=True)
    live.start()

    tool_items: list[str] = []
    response_text = ""
    response_started = False

    try:
        streamed_result = await run_evernote_agent(mcp_server, conversation, stream=True)

        async for event in streamed_result.stream_events():
            if event.type == "raw_response_event":
                if isinstance(event.data, ResponseTextDeltaEvent):
                    # Once response starts, stop live display
                    if not response_started:
                        response_started = True
                        live.stop()
                    response_text += event.data.delta
                    print(event.data.delta, end="", flush=True)

            elif event.type == "run_item_stream_event":
                if event.name == "tool_called" and not response_started:
                    # Add tool to live display with spinner
                    tool_name = event.item.raw_item.name
                    if tool_name not in tool_items:
                        tool_items.append(tool_name)

                    # Update live display with all active tools
                    spinners = [
                        Spinner("dots", text=f"üîß {name}")
                        for name in tool_items
                    ]
                    live.update(Group(*spinners))

        if not response_started:
            live.stop()

        print()  # New line after streaming

    finally:
        if live.is_started:
            live.stop()

    return response_text, conversation_history
```

**R√©sultat visuel** :
```
üîß createSearch ‚†ã
üîß getNoteContent ‚†ã
AI is typing...
```

### Le√ßons Async

1. **Async obligatoire** : Toujours `async def` + `await` pour les agents
2. **Streaming UX** : Utiliser Rich Live pour afficher l'activit√© en temps r√©el
3. **Context Manager** : `async with mcp_server as server:` garantit cleanup
4. **Session scope** : Cr√©er MCP server une fois, r√©utiliser pour toutes les requ√™tes
5. **Error handling** : `try/finally` pour cleanup m√™me en cas d'erreur

---

## üöß Les Limites Actuelles du MCP

### 1. **Deux Mondes S√©par√©s : Local vs Cloud**

**Probl√®me** : Les outils locaux ne peuvent pas facilement interagir avec les services cloud, et vice versa.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Local (Desktop)       ‚îÇ     ‚îÇ   Cloud (SaaS)           ‚îÇ
‚îÇ                         ‚îÇ     ‚îÇ                          ‚îÇ
‚îÇ ‚úÖ Claude Code          ‚îÇ     ‚îÇ ‚ùå Claude Code           ‚îÇ
‚îÇ ‚úÖ Cursor               ‚îÇ     ‚îÇ ‚ùå Cursor                ‚îÇ
‚îÇ ‚úÖ MCP Stdio (Docker)   ‚îÇ     ‚îÇ ‚ùå MCP Stdio             ‚îÇ
‚îÇ ‚ùå ChatGPT              ‚îÇ     ‚îÇ ‚úÖ ChatGPT               ‚îÇ
‚îÇ ‚ùå Le Chat              ‚îÇ     ‚îÇ ‚úÖ Le Chat               ‚îÇ
‚îÇ ‚ùå MCP SSE distant      ‚îÇ     ‚îÇ ‚úÖ MCP SSE distant       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Cons√©quence** :
- ChatGPT/Le Chat ne peuvent pas acc√©der aux outils locaux (Evernote via Docker, filesystem local)
- Les outils locaux n√©cessitent des configurations complexes pour acc√©der au cloud (OAuth, URLs, etc.)

### 2. **Authentification Complexe**

**Probl√®me** : Chaque serveur MCP distant n√©cessite sa propre configuration OAuth.

**Exemple HubSpot** :
- CLIENT_ID, CLIENT_SECRET √† configurer
- Serveur local pour callback OAuth (port 3000-3009)
- Gestion du refresh token
- Persistance du token entre sessions

**Pas encore de standard** : Chaque service MCP impl√©mente son propre flow OAuth.

### 3. **Setup Non-Trivial**

**Pour utiliser HubSpot MCP** :
1. Cr√©er une app HubSpot (portal d√©veloppeur)
2. Configurer les scopes OAuth
3. Obtenir CLIENT_ID et CLIENT_SECRET
4. Configurer redirect URI (http://localhost:3000/oauth-callback)
5. Impl√©menter le flow OAuth complet
6. G√©rer la persistance et le refresh

**R√©f√©rence** : [HubSpot MCP Integration Guide](https://developers.hubspot.com/docs/apps/developer-platform/build-apps/integrate-with-hubspot-mcp-server)

### 4. **Framework Encore Jeune**

**Critique courante** : R√©inventer la roue

> "MCP r√©invente ce qui existe d√©j√† avec OpenAPI, OAuth, function calling..." - [Article critique](https://raz.sh/blog/2025-05-02_a_critical_look_at_mcp)

**R√©ponse pragmatique** :

**Avantages MCP** :
- ‚úÖ **Standardisation** : Format unifi√© pour exposer tools aux agents
- ‚úÖ **Documentation int√©gr√©e** : Les agents comprennent automatiquement les tools
- ‚úÖ **Vendor support** : Anthropic, OpenAI, etc. investissent dans l'√©cosyst√®me
- ‚úÖ **Acc√®s local** : Claude Code et Cursor peuvent utiliser des outils locaux (filesystem, Docker)

**Limitations** :
- ‚ùå Pas encore mature (spec change r√©guli√®rement)
- ‚ùå Peu d'outils natifs (beaucoup de "hello world" examples)
- ‚ùå Probl√®mes de s√©curit√© non compl√®tement r√©solus
- ‚ùå Performance √† am√©liorer (latence, overhead)

### 5. **S√©curit√© : Mod√®le de Confiance Implicite**

**Probl√®me** : Un agent avec acc√®s MCP peut ex√©cuter n'importe quel tool.

**Exemple** : Un agent avec acc√®s √† `filesystem` peut lire/√©crire n'importe quel fichier.

**Mitigation actuelle** :
- Sandbox via Docker (isolation processus)
- Scopes OAuth limit√©s (read-only, specific objects)
- Instructions claires dans les prompts agents

**√Ä suivre** : Authentification fine-grained, autorisation par tool.

---

## üí° Patterns et Bonnes Pratiques

### 1. **Architecture Modulaire**

**S√©parer les responsabilit√©s** :
```
src/
‚îú‚îÄ‚îÄ dataprep/
‚îÇ   ‚îú‚îÄ‚îÄ models.py              # Sch√©mas Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ knowledge_db.py        # Gestionnaire thread-safe
‚îÇ   ‚îú‚îÄ‚îÄ mcp_functions.py       # Fonctions m√©tier
‚îÇ   ‚îî‚îÄ‚îÄ core.py               # Legacy (intouch√©)
‚îú‚îÄ‚îÄ mcp/
‚îÇ   ‚îî‚îÄ‚îÄ dataprep_server.py    # Interface MCP
‚îî‚îÄ‚îÄ config.py                 # Configuration centralis√©e
```

**Avantages** :
- Testabilit√© (chaque module ind√©pendant)
- Maintainability (single responsibility)
- √âvolutivit√© (ajout de features sans tout casser)

### 2. **Configuration Centralis√©e**

**config.yaml** :
```yaml
data:
  urls_file: "urls.txt"
  knowledge_db_path: "data/knowledge_db.json"
  local_storage_dir: "data/"

mcp:
  container_name: "evernote-mcp-server-..."
  timeout: 30

openai:
  model: "gpt-4o-mini"
  temperature: 0.3
```

**Acc√®s** :
```python
from src.config import get_config

config = get_config()
db_manager = KnowledgeDBManager(config.data.knowledge_db_path)
```

### 3. **Logging Structur√©**

**Pattern** :
```python
import logging

logger = logging.getLogger(__name__)

logger.info("Document t√©l√©charg√©", extra={
    "url": url,
    "filename": filename,
    "content_length": len(content),
    "keywords_count": len(keywords)
})
```

**Avantages** :
- Debugging facilit√© (structured logs)
- Monitoring (m√©triques exportables)
- Tra√ßabilit√© (audit trail)

### 4. **Optimisation Intelligente**

**Principe** : R√©utiliser plut√¥t que re-cr√©er.

**Exemples** :
- Stocker `openai_file_id` pour √©viter re-uploads
- Cacher `tools_list` du MCP server (`cache_tools_list=True`)
- Singleton pour gestionnaires (KnowledgeDBManager, OAuthManager)

### 5. **Tests d'Int√©gration**

**Pattern** : Isolation compl√®te avec temp directories.

```python
import pytest
import tempfile
from pathlib import Path

@pytest.fixture
def temp_config():
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        config = get_config()
        config.data.knowledge_db_path = str(temp_path / "test_kb.json")
        config.data.local_storage_dir = str(temp_path / "data")
        yield config

def test_download_and_store_url(temp_config):
    filename = download_and_store_url("https://example.com", temp_config)
    assert filename.endswith(".md")
    assert Path(temp_config.data.local_storage_dir / filename).exists()
```

### 6. **Error Handling Graceful**

**Principe** : Ne jamais crasher l'agent, toujours un fallback.

```python
def _extract_keywords_with_llm(doc, config) -> List[str]:
    try:
        # LLM extraction
        response = client.chat.completions.create(...)
        keywords = ...
        return keywords
    except Exception as e:
        logger.warning(f"LLM keyword extraction failed: {e}, using fallback")
        return _extract_basic_keywords(doc)  # Fallback simple

def _extract_basic_keywords(doc) -> List[str]:
    # Extraction basique (titre, mots significatifs)
    words = doc.page_content.split()
    return [w for w in words if len(w) > 5][:10]
```

---

## üìä M√©triques et Monitoring

### Que Mesurer ?

**Performance** :
- ‚è±Ô∏è Temps de r√©ponse par requ√™te
- üìä Nombre de tool calls par conversation
- üîÑ Taux de r√©utilisation (uploads, cache)

**Co√ªts** :
- üí∞ Nombre d'appels API OpenAI
- üìÅ Taille des fichiers upload√©s
- ‚òÅÔ∏è Utilisation vector stores

**Fiabilit√©** :
- ‚úÖ Taux de succ√®s des operations
- ‚ùå Taux d'√©chec et types d'erreurs
- üîÑ Nombre de retries n√©cessaires

### Exemple : DataPrep Metrics

```python
class UploadResult(BaseModel):
    vectorstore_id: str
    total_files_requested: int
    upload_count: int = 0      # Nouveaux uploads
    reuse_count: int = 0       # Fichiers r√©utilis√©s
    attach_success_count: int = 0
    attach_failure_count: int = 0
    files_uploaded: List[dict]
    files_attached: List[dict]

# Usage
result = upload_files_to_vectorstore(inputs, config, "research-vs")
print(f"Optimisation: {result.reuse_count}/{result.total_files_requested} r√©utilis√©s")
# Optimisation: 6/6 fichiers r√©utilis√©s (100% √©conomie!)
```

---

## üéØ Recommandations Finales

### Quand Utiliser MCP ?

‚úÖ **OUI, utiliser MCP si** :
- Vous d√©veloppez avec Claude Code, Cursor (stdio local)
- Vous voulez standardiser l'acc√®s aux tools pour plusieurs agents
- Vous cr√©ez un serveur de tools personnalis√© pour votre √©quipe
- Vous voulez b√©n√©ficier de l'√©cosyst√®me Anthropic/OpenAI

‚ùå **NON, √©viter MCP si** :
- Vous avez juste besoin d'appeler une API REST simple (function calling direct)
- Vous voulez maximiser la performance (overhead MCP non-n√©gligeable)
- Vous avez besoin de s√©curit√© fine-grained (mod√®le de confiance MCP trop large)
- Vous travaillez sur des syst√®mes critiques (MCP encore jeune)

### Checklist de D√©marrage

Avant de vous lancer dans un projet MCP :

**1. Architecture** :
- [ ] D√©finir si stdio (local) ou SSE/HTTP (cloud)
- [ ] Identifier les tools n√©cessaires
- [ ] Planifier l'authentification (OAuth si besoin)

**2. Setup** :
- [ ] Installer les d√©pendances (`agents`, `fastmcp`)
- [ ] Configurer les environment variables
- [ ] Tester la connexion MCP de base

**3. Impl√©mentation** :
- [ ] Utiliser MCPServerStdio/MCPServerStreamableHttp natifs
- [ ] Impl√©menter avec async context managers
- [ ] Ajouter logging structur√©
- [ ] G√©rer les erreurs avec fallbacks

**4. Tests** :
- [ ] Tests d'int√©gration avec isolation
- [ ] Tests de performance (baseline vs optimized)
- [ ] Tests de stress (concurrent access)

**5. Documentation** :
- [ ] Documenter le setup (auth, config)
- [ ] Fournir des exemples d'usage
- [ ] Documenter les limitations

### Ressources Utiles

**Documentation Officielle** :
- [MCP Quickstart](https://modelcontextprotocol.io/docs/getting-started/intro)
- [Anthropic MCP Course](https://anthropic.skilljar.com/introduction-to-model-context-protocol)
- [DeepLearning.AI MCP Course](https://www.deeplearning.ai/short-courses/build-ai-apps-with-mcp-server-working-with-box-files/)

**Exemples Pratiques** :
- [HubSpot MCP Integration](https://developers.hubspot.com/docs/apps/developer-platform/build-apps/integrate-with-hubspot-mcp-server)
- [MCP Servers Catalog](https://github.com/modelcontextprotocol/servers)
- [FastMCP Framework](https://github.com/jlowin/fastmcp)

**Critiques et Analyses** :
- [A Critical Look at MCP](https://raz.sh/blog/2025-05-02_a_critical_look_at_mcp)
- [MCP Security Considerations](https://modelcontextprotocol.io/docs/security)

---

## üìù Conclusion

Le **Model Context Protocol (MCP)** est un framework **prometteur mais encore jeune** pour standardiser l'acc√®s aux tools pour les agents LLM.

**Nos le√ßons apprises** sur 3 projets r√©els :

1. **Cycle de vie MCP** : Utiliser les clients natifs avec async context managers
2. **OAuth** : Impl√©menter avec singleton + token refresh + persistance
3. **Serveurs custom** : FastMCP + SSE pour services cloud
4. **Async patterns** : Toujours async/await + streaming pour UX
5. **Optimisations** : R√©utiliser plut√¥t que re-cr√©er (cache, IDs persistants)

**Le MCP n'est pas la panac√©e** :
- Deux mondes (local vs cloud) encore s√©par√©s
- Setup OAuth complexe
- Framework encore jeune (breaking changes fr√©quents)
- S√©curit√© √† am√©liorer

**Mais il a du potentiel** :
- Standardisation n√©cessaire
- Support vendor (Anthropic, OpenAI)
- √âcosyst√®me en croissance
- Exp√©rience d√©veloppeur en am√©lioration

**Notre recommandation** : Adoptez le MCP pour des projets non-critiques, exp√©rimentez, contribuez √† l'√©cosyst√®me, mais gardez une architecture modulaire pour pouvoir pivoter si n√©cessaire.

---

_Document bas√© sur les impl√©mentations r√©elles dans AI-Agent-Casebook (branch: feature/evernote-chatbot-mcp)_

**Auteurs** : Pierre Bittner + Claude (Co-Authored-By: Claude <noreply@anthropic.com>)

**Date** : Octobre 2025

**Licence** : Open Source (voir LICENSE du projet)
