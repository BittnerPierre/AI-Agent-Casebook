# Release Notes - August 2025
## AI-Agent-Casebook: GPT-5 Integration & Technical Infrastructure Cleanup

### üöÄ Overview
This release represents a **technical infrastructure cleanup and GPT-5 integration cycle** focused on making GPT-5 compatible while standardizing the codebase. The work was concentrated in a **single major commit** on **August 26th, 2025** (`c31d5e7` - PR #135), addressing import path standardization, dependency updates, and critical compatibility fixes.

**Key Achievement**: Successful GPT-5 integration with configurable model support, requiring operational changes due to synchronous call limitations.

---

## üìÖ Development Context

### August 2025: Technical Debt & Integration Phase
- **Single Major Commit**: August 26th (`c31d5e7`) - comprehensive integration
- **Focus**: Infrastructure cleanup rather than new feature development  
- **GitHub Issues Addressed**: #127, #137 (partial), #136 (partial)
- **Issues Remaining Open**: #134, #138 (customer onboarding and evaluator failures)

---

## ü§ñ GPT-5 Integration & Model Support

### New Model Additions (app/core/base.py)
```python
# Added to SupportedModel enum:
GPT_5_MINI = "gpt-5-mini"              # üÜï Primary GPT-5 model
MISTRAL_MEDIUM = "mistral-medium-latest"  # üÜï Additional Mistral variant
CLAUDE_SONNET_4_O = "claude-sonnet-4-0"  # üÜï Claude 4.0

# Renamed for consistency:
CLAUDE_SONNET_3_7 = "claude-3-7-sonnet-latest"  # was CLAUDE_SONNET
CLAUDE_HAIKU_3_5 = "claude-3-5-haiku-latest"    # was CLAUDE_HAIKU
```

### Model-Specific Configuration System ‚≠ê **NEW FEATURE**
**Major Improvement**: VideoScript models now configurable via config files instead of hardcoded values

**New Configuration Files**:
- `config-gpt-5-min.ini` - GPT-5 optimized settings
- `config-gpt-4o-mini.ini` - GPT-4o Mini configuration  
- `config_mistral-small.ini` - Mistral Small configuration

**VideoScript Configuration Example**:
```ini
[VideoScript]
# Separate model configuration for each component
planner_model = gpt-5-mini          # Agents SDK model (litellm format)
worker_model = GPT_5_MINI           # Worker agent model (enum format)
producer_model = GPT_5_MINI         # Producer agent model (enum format)
tags = ["gpt-5-mini"]
```

**Impact**: Easy model comparison without code changes - critical for testing different models against same workflows.

---

## üîß Critical Technical Fixes

### LangGraph API Compatibility Issues
**Problem**: LangGraph now detects synchronous calls within async functions and blocks them
**Impact**: GPT-5 and Agents SDK make internal sync calls we cannot control
**Solution**: **Operational change required**
```bash
# Old command (no longer works):
poetry run langgraph dev

# New required command:
poetry run langgraph dev --allow-blocking
```

### LangSmith API Call Updates  
**Problem**: Sync LangSmith API calls within async functions flagged by new LangGraph checks
**Solution**: Updated LangSmith API calls to async patterns where needed
**Files**: Video script modules with LangSmith integration

### Corrective RAG (CRAG) Import Fixes
**Problem**: CRAG system had broken imports and outdated dependencies
**Fixes Applied**:
```python
# Fixed import in app/crag/agents.py:
from langchain_community.tools import TavilySearchResults  # ‚ùå Old
from langchain_tavily import TavilySearch                  # ‚úÖ New

# Fixed all import paths:
from ai_agents import AbstractAgent        # ‚ùå Old  
from app.ai_agents import AbstractAgent    # ‚úÖ New

# Added configuration-driven model selection:
_model_name = _config.get('CorrectiveRAG', 'model', fallback="MISTRAL_SMALL")
model_name = SupportedModel[_model_name]
```

---

## üèóÔ∏è Infrastructure Standardization

### Massive Import Path Cleanup
**Scope**: **Systematic fix across entire codebase** - one of the largest changes
**Pattern**: Added `app.` prefixes to all relative imports

**Examples of Changes**:
```python
# Tests (all test files updated):
from core.base import SupportedModel                    # ‚ùå Old
from app.core.base import SupportedModel               # ‚úÖ New

from customer_onboarding.agents import EligibilityAgent  # ‚ùå Old  
from app.customer_onboarding.agents import EligibilityAgent  # ‚úÖ New

# Application modules:
from ai_agents.base import Agent                        # ‚ùå Old
from app.ai_agents.base import Agent                   # ‚úÖ New
```

**Files Modified**: 25+ application files, 15+ test files, configuration updates

### Test Infrastructure Modernization
**pytest.ini Configuration Added**:
```ini
[tool.pytest.ini_options]
pythonpath = [".", "app", "tests"]
testpaths = ["tests"] 
python_files = ["test_*.py", "*_test.py"]
addopts = "--import-mode=importlib"
filterwarnings = [
    "ignore::DeprecationWarning",
    "ignore::PendingDeprecationWarning"
]
```

**Agent Initialization Updates**: All test agents now require `name` parameter
```python
# Old pattern:
agent = EligibilityAgent(model=model)

# New pattern:
agent = EligibilityAgent(name="EligibilityAgent", model=model)
```

**LangGraph Compatibility**: Removed deprecated `AddableValuesDict` usage from simulation utils

### Package Structure Fix
**pyproject.toml Correction**:
```toml
# Old (incorrect):
packages = [{ include = "customer_onboarding", from = "app" }]

# New (correct):
packages = [{ include = "app" }]
```

---

## üì¶ Dependency Management & Updates

### Major Version Updates
```toml
# Key dependency changes:
openai-agents = {extras = ["litellm"], version = "^0.2.9"}  # was >=0.0.14
python = ">=3.12,<=3.13"                                   # was >=3.12,<4.0
llama-index = "^0.12.52"                                   # was >=0.12.11
```

### New Dependencies
```toml
langchain-voyageai = "^0.1.7"    # Voyage embeddings framework (ready, not activated)
langchain-tavily = "^0.2.11"     # Tavily search for CRAG fixes
langgraph-api = "^0.2.137"       # Enhanced LangGraph API capabilities
```

### Configuration Dependencies
```toml
# Enhanced tooling:
langgraph-cli = {extras = ["inmem"], version = "^0.2.10"}
mcp = {extras = ["cli"], version = "^1.7.1"}
```

---

## ‚ö° Performance Optimizations

### VideoScript Performance Tuning (app/video_script/configuration.py)
```python
# Optimized defaults:
max_search_results: int = 3        # was 10 - reduced for better focus
max_revision: int = 1              # was 2 - streamlined revision process
```

**Impact**: Faster VideoScript execution with more focused search results

---

## üìã Issue Status & Limitations

### ‚úÖ Issues Resolved  
- **#127**: GPT-5 tool choice compatibility - Model integration completed
- **#137**: CRAG empty vector store - Import fixes and config foundation added
- **Import Issues**: Systematic cleanup of import paths across codebase

### üü° Partially Addressed
- **#136**: Planner Evaluator - Infrastructure ready, but core issues may remain  
- **#139**: LangSmith Agents SDK observability - AsyncClient imports added

### ‚ùå Issues Still Open
- **#134**: GPT-5 customer onboarding function calling errors - **NOT FIXED**
- **#138**: Application failure when plan rejected by evaluator - **NOT FIXED**
- **#141**: Large PDF file embedding rate limits - Needs batching solution

### üöß Known Limitations
- **Blocking Call Requirement**: Must use `--allow-blocking` with langgraph dev
- **CRAG Document Loading**: Configuration foundation only, dynamic loading not implemented
- **Voyage AI Embeddings**: Framework ready but requires paid subscription

---

## üéØ New Features Summary

### 1. **Configurable VideoScript Models** ‚≠ê
**Before**: Models hardcoded in code, required code changes to test different models
**After**: Full model configuration via config files
```ini
[VideoScript]
planner_model = gpt-5-mini    # Easy to change for testing
worker_model = GPT_5_MINI     # Compare model performance
producer_model = GPT_5_MINI   # Without code modifications
```

### 2. **Model-Specific Configuration Files**
Pre-configured settings for optimal performance per model:
- GPT-5 settings in `config-gpt-5-min.ini`
- GPT-4o settings in `config-gpt-4o-mini.ini`  
- Mistral settings in `config_mistral-small.ini`

### 3. **Enhanced CRAG Configuration**
```ini
[CorrectiveRAG]
model = GPT_5_MINI
# preload_urls = # Future feature - framework ready
```

---

## üöÄ Usage Instructions

### Starting the Application
```bash
# Required for GPT-5 and Agents SDK compatibility:
poetry run langgraph dev --allow-blocking --config config-gpt-5-min.ini

# For different models:
poetry run langgraph dev --allow-blocking --config config-gpt-4o-mini.ini
poetry run langgraph dev --allow-blocking --config config_mistral-small.ini
```

### Testing Different Models
```bash
# Easy model comparison - no code changes needed:
poetry run langgraph dev --allow-blocking --config config-gpt-5-min.ini      # GPT-5 test
poetry run langgraph dev --allow-blocking --config config-gpt-4o-mini.ini    # GPT-4o test  
poetry run langgraph dev --allow-blocking --config config_mistral-small.ini  # Mistral test
```

---

## ‚ö†Ô∏è Breaking Changes & Migration

### Operational Changes
- **REQUIRED**: Must use `--allow-blocking` flag with `langgraph dev`
- **Configuration**: Use model-specific config files for optimal performance
- **Import Paths**: All imports now require `app.` prefixes (already fixed in codebase)

### Test Execution
```bash
# Updated test commands:
poetry run pytest tests/ -v                    # All tests
poetry run pytest tests/video_script/ -v       # VideoScript tests
poetry run pytest tests/customer_onboarding/ -v # Customer onboarding tests
```

### Agent Initialization
All custom agents now require `name` parameter:
```python
agent = YourAgent(name="AgentName", model=model, **kwargs)
```

---

## üîç Technical Architecture

### Model Configuration Flow
```
Config File ‚Üí load_config() ‚Üí Model Selection ‚Üí Agent Initialization
     ‚Üì              ‚Üì              ‚Üì                    ‚Üì
config-gpt-5-min.ini ‚Üí GPT_5_MINI ‚Üí VideoScript ‚Üí planner_model: gpt-5-mini
```

### Import Architecture Standardization
```
Before: Relative imports (ai_agents.base)
After:  Absolute imports (app.ai_agents.base)
Result: Consistent import patterns, better IDE support, clearer dependencies
```

---

## üìä Development Metrics

### Code Changes Summary
- **Files Modified**: 65+ files across application and tests
- **New Configuration Files**: 3 model-specific configs
- **Import Path Updates**: 100+ import statements standardized
- **Dependency Updates**: 10+ package version changes
- **Test Infrastructure**: Complete pytest configuration overhaul

### Quality Improvements
- **Import Consistency**: 100% standardized import paths
- **Configuration Flexibility**: Model switching without code changes
- **Test Reliability**: Enhanced pytest configuration and compatibility
- **Dependency Currency**: Latest compatible versions across stack

---

## üéØ Strategic Impact

### Model Experimentation Enablement
**Critical capability unlocked**: Easy model comparison for performance evaluation
- Switch between GPT-5, GPT-4o, Claude 4.0, Mistral models via config
- Compare model performance on identical workflows  
- No code changes required for model testing

### Technical Debt Reduction
- **Import Path Standardization**: Eliminated relative import inconsistencies
- **Configuration Management**: Centralized model and component configuration
- **Test Infrastructure**: Modern pytest setup with proper path resolution
- **Dependency Management**: Current versions with proper compatibility constraints

### Foundation for Future Work
- **CRAG Enhancement**: Configuration foundation for document pre-loading
- **Voyage AI Ready**: Framework prepared for advanced embeddings
- **LangSmith Integration**: AsyncClient foundation for enhanced observability

---

## ü§ù Development Notes

**Primary Developer**: Pierre Bittner <pierre@bittner.fr>

**Development Approach**: 
- Comprehensive technical infrastructure cleanup
- Single large commit addressing multiple related compatibility issues
- Focus on standardization and GPT-5 integration rather than new features

**AI Collaboration**: 
- ü§ñ Generated with [Claude Code](https://claude.ai/code)
- Co-Authored-By: Claude <noreply@anthropic.com>

**Key Success**: Successfully integrated GPT-5 while establishing configurable model architecture for easy comparison and testing.

---

*This release establishes a **solid technical foundation** for model experimentation and comparison while integrating GPT-5 capabilities. The focus on infrastructure cleanup and standardization enables more efficient development and testing workflows moving forward.*