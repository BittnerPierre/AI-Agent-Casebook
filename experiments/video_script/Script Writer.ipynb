{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d507716-09d2-4b73-93e6-a139b349f1de",
   "metadata": {},
   "source": [
    "# Building an Agentic System for YouTube Script Writing with LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ec9162-84cb-46f9-bb4e-7d64c57e62ed",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Automating YouTube script writing is an ideal use case to showcase the power of agentic systems. In this article, we will build an agentic system step by step using LangGraph and LangChain, following an iterative approach.\n",
    "\n",
    "We will use Mistral Small 3 as our primary LLM. This choice is strategic as agentic systems allow us to avoid relying on very large models like GPT-4o or Large Reasoning Models (LRMs) such as O1 or DeepSeek. With this approach, we can achieve advanced results while being more efficient in terms of computation and resources.\n",
    "\n",
    "**Mistral Small 3** covers all our need for our agentic use case: \n",
    "- Low-latency function calling,\n",
    "- robust structured output,\n",
    "- competitive instuction following,\n",
    "- fast-response conversational assistance,\n",
    "- General Knowlegde performance that rivals models three times larger.\n",
    "\n",
    "We will explore how to transition from a single LLM-based writing assistant to a multi-agent system capable of collaborating to produce a high-quality script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597c8d42-9742-416d-afea-d42a0eb2896c",
   "metadata": {},
   "source": [
    "## What You Will Learn\n",
    "- The basics of agentic systems and why they matter\n",
    "- How to create a **multi-agent** system with LangGraph\n",
    "- How to evaluate agents and improve their quality\n",
    "- How to use **Mistral Small 3** for efficient structured output\n",
    "- How to implement a **supervisor** to coordinate agent collaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478701cc-1d02-43f5-9c4c-7a524e890150",
   "metadata": {},
   "source": [
    "### **Understanding What an Agentic System Is (Collaboration of Agents, Not Just Function Calling)**\n",
    "\n",
    "An **agentic system** is fundamentally about **collaboration between multiple autonomous agents** to accomplish a complex task. Unlike a traditional **function-calling approach**, where a single model or function sequentially processes inputs, an **agentic system** enables **distributed decision-making**, **specialized roles**, and **dynamic workflow adjustments** based on real-time results.\n",
    "\n",
    "In this tutorial, we are **not focusing on function calling**, as it plays a minimal role in our implementation. Instead, we aim to build an **end-to-end agentic solution** with **fundamental capabilities**, showcasing how independent agents can work together in a structured, modular way.\n",
    "\n",
    "### **Why Focus on the Basics?**\n",
    "LangGraph’s official documentation often highlights **advanced features** such as:\n",
    "- **Human-in-the-loop interventions** (where users can manually approve, edit, or intervene in workflows),\n",
    "- **Memory management** (persistent state tracking across interactions),\n",
    "- **Streaming outputs** (real-time updates from LLMs),\n",
    "- **Complex multi-agent workflows** with intricate dependencies and decision-making.\n",
    "\n",
    "These advanced features are **powerful but can overwhelm beginners** who are just getting started with **agentic systems**. \n",
    "\n",
    "### **The Goal of This Tutorial**\n",
    "- Provide a **clear, accessible** introduction to **multi-agent system construction** using **LangGraph**.\n",
    "- Focus on **core principles**: agent coordination, modularity, and workflow execution.\n",
    "- **Avoid unnecessary complexity** while still demonstrating the **power of agentic architectures**.\n",
    "\n",
    "This step-by-step approach ensures that **readers first master the fundamentals** before diving into **more advanced agentic capabilities**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cef887-b134-42fa-9312-0e0d9a7dd535",
   "metadata": {},
   "source": [
    "## Chapter 1: Understanding the Limitations of Classical Approaches\n",
    "\n",
    "### The Problem with Classical Writing Assistants\n",
    "\n",
    "Early iterations of writing assistants relied on a single LLM with a RAG knowledge base. Unfortunately, these systems had limitations:\n",
    "\n",
    "- Excessive reliance on prompts\n",
    "- Lack of coherence in the generated script\n",
    "= Difficulty integrating user feedback\n",
    "\n",
    "### Towards an Agentic Approach\n",
    "\n",
    "Instead of asking a single model to handle everything, we will break down the writing process into multiple specific tasks assigned to specialized agents:\n",
    "\n",
    "- **Planning**: Defining chapters and the overall script structure\n",
    "- **Researcher**: Gathering relevant information\n",
    "- **Writer**: Generating the content for each section\n",
    "- **Reviewer**: Editing and validating the script\n",
    "- **Supervisor**: Managing the workflow and final validation"
   ]
  },
  {
   "attachments": {
    "2f47c12c-ec76-4a66-9e60-48aebec4b465.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "2d33cd05-5231-466f-afd5-e43f8ffb24e1",
   "metadata": {},
   "source": [
    "![video_script_state_graph.png](attachment:2f47c12c-ec76-4a66-9e60-48aebec4b465.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1f25ad-a850-4942-8d98-de15c1098fd9",
   "metadata": {},
   "source": [
    "## Chapter 2: Introduction to LangChain Concepts\n",
    "\n",
    "Before diving into LangGraph, it is crucial to understand the core LangChain concepts that will be used in nodes:\n",
    "\n",
    "- **Prompt Templates**: Structuring effective prompts for agent interactions.\n",
    "- **LLM with Structured Output**: Ensuring predictable responses.\n",
    "- **LLM with Tools**: Allowing agents to interact with external sources.\n",
    "- **Prompt Hub from LangSmith**: Reusing and managing prompts efficiently.\n",
    "\n",
    "We will also explore how to test individual nodes before integrating them into a full graph-based workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a10aca0-e34a-4305-8a63-edf500a68c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Import     #\n",
    "##############\n",
    "from typing import TypedDict, Literal, Annotated, List\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b0f8e6-7920-47b8-9088-40c8acb93890",
   "metadata": {},
   "source": [
    "We now load LangChain MistralAI client that we will use throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b8dcdb-47e6-4d2d-84dd-3babc184ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "################\n",
    "# AUTH KEY     #\n",
    "################\n",
    "\n",
    "# Import key from .env\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# You'll need following key in you .env\n",
    "# MISTRAL_API_KEY=vx...\n",
    "# for LC Prompt Hub\n",
    "# LANGCHAIN_API_KEY=lsv2_pt...\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"MISTRAL_API_KEY\")\n",
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56756d98-9e31-41a7-b265-4dec657a2462",
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# COMMON     #\n",
    "################\n",
    "\n",
    "# Mistral Small 3 available on Mistral AI 'La Platforme'\n",
    "llm = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad359b46-80ef-4de6-a914-c949278eefde",
   "metadata": {},
   "source": [
    "Here is the code of our first agent: the researcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29d2051-feb5-43bc-8ee7-74f2f6857b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# RESEARCHER AGENT #\n",
    "####################\n",
    "\n",
    "# Define output format\n",
    "class Research(TypedDict):\n",
    "    research: str\n",
    "    comment: str\n",
    "\n",
    "\n",
    "researcher_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            f\"\"\"\n",
    "            You are the **Researcher** in a team responsible for scriptwriting YouTube videos.\n",
    "            Your role is to **gather, verify, and organize** relevant information to support scriptwriter in producing accurate and engaging content.  \n",
    "            \n",
    "            ### Responsibilities:\n",
    "            - Provide **exhaustive, detailed, well-organized, contrasted and factual** information\n",
    "            to feed the writer for all topics on the agenda. \n",
    "            - **No assumption or generic statements.** Only verifiable, specific facts or knowlegde.\n",
    "            - **Incorporate feedback** to refine and improve your research.  \n",
    "            - **You do not write the script.**\n",
    "            - **You do not plan the agenda.**\n",
    "            - **You do not review or make critics.**\n",
    "\n",
    "            ### Constraint:\n",
    "            The scriptwriter will not have access to any other source than your research.\n",
    "            - Ensure that all necessary information is provided in your response.  \n",
    "            - Do not assume the scriptwriter knows background details—explain key concepts where needed.  \n",
    "            - Use reliable **sources** whenever possible to support claims.\n",
    "            \n",
    "            #### Expected Output Format:\n",
    "            1. **Research**  \n",
    "               - Organize your research with **numbered sections, subsections, bullet points, and hyphens** following the agenda for clarity.  \n",
    "               - Include **sources** whenever possible.  \n",
    "            2. **Comment**  \n",
    "               - Use plain text to add **research notes** or respond to feedback.  \n",
    "               - If informations are missing, state it here.\n",
    "            \n",
    "            #### Additional Notes:\n",
    "            - Maintain a **clear and structured** format for readability.  \n",
    "            - Avoid using **JSON, XML, or code-like formats.** Stick to plain text.  \n",
    "            \"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "researcher = researcher_prompt | llm.with_structured_output(Research)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4727714-f86d-4f95-9e11-5ced9a28a33c",
   "metadata": {},
   "source": [
    "This is a simple LLM chain with structured output. However, in real-world applications, you’ll likely need to extend it by integrating function calling or RAG (Retrieval-Augmented Generation) to enhance accuracy.\n",
    "\n",
    "You can take inspiration from the [Research Team](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/hierarchical_agent_teams/?h=#research-team) of [Hierarchical Agent Teams](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/hierarchical_agent_teams/?h=#hierarchical-agent-teams) on LangGraph Documentations.\n",
    "\n",
    "We will keep 'research agent' as is for simplification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7027993-05f8-4898-b600-9a4848f5a66c",
   "metadata": {},
   "source": [
    "Let's test this researcher agent. We define a conversation from a 'Human' and the 'Planner' ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3196799-9efc-4191-a9cb-be9e4ed65afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emulate a conversation\n",
    "\n",
    "input = [\n",
    "        (\"human\", \"\"\"I would like a two-chapter video, 2 minutes long, containing 450 words on the topic\n",
    "            'AI will not take your job. Those who use AI will!'\"\"\"),\n",
    "        (\"assistant\", \"\"\"Here's a suggested agenda for your 2-chapter video on 'AI will not take your job. Those who use AI will!'\n",
    "\n",
    "    ### Chapter 1\n",
    "    1. **Title**\n",
    "    AI will not take your job. Those who use AI will! (200 words):\n",
    "    \n",
    "    2. **Brief**\n",
    "    Introduction of the video, presentation of the topic, and key points to be covered.\n",
    "    \n",
    "    3. **Covered Topics**\n",
    "    - Understanding AI's role in the job market\n",
    "    - The benefits of AI for workers\n",
    "    - The skills needed to work with AI\n",
    "\n",
    "    ### Chapter 2\n",
    "    1. **Title**\n",
    "    AI and Career Opportunities (250 words):\n",
    "    \n",
    "    2. **Brief**\n",
    "    Presentation of companies that are succeeding thanks to AI, the skills in demand, and career opportunities.\n",
    "    \n",
    "    3. **Covered Topics**\n",
    "    - Companies that have succeeded with AI\n",
    "    - Skills sought by employers\n",
    "    - Career opportunities with AI\"\"\"),\n",
    "        (\"human\", \"Provide research for the video.\"),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95923a30-4346-496d-859c-380c6cda0481",
   "metadata": {},
   "source": [
    "To call the agent, simply provide the conversation history along with a team description as input to the ```invoke``` method.\n",
    "\n",
    "As our agent is a LangChain runnable, you could stream, batch or make asynchronous call. Sweet! But we just invoke here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc57f53-3777-4134-b735-44542f1bd74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_res = researcher.invoke(input={\"messages\": input})\n",
    "print(researcher_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93fc1f3-edcc-4cdb-add8-a4bf1e4a4722",
   "metadata": {},
   "source": [
    "You should get 2-chapter research and a comment. The quality of research may vary. This is 'normal' based on the stochastic nature of LLM outputs.\n",
    "\n",
    "This is fine at this stage. We will add a 'reviewer' agent later that will control the quality of research content.  Also, we will move our scriptwriting workflow to operate chapter per chapter to mitigate this by letting the agent work on a smaller chunk of task.\n",
    "\n",
    "Next, we will see an important practice in agentic agent and will introduce the concept of how an llm agent can 'review' the work of another one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de362d8-217d-43ce-b8f2-c4eeaddf6c30",
   "metadata": {},
   "source": [
    "### Good Practice #1: Agent Evaluation\n",
    "\n",
    "It is essential to have a robust evaluation system in place from the beginning to ensure steady and good progress while developping your agentic workflow.\n",
    "\n",
    "As llm answer can change we will use llm-as-judge to evaluate our agent answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fdb4e0-b744-410c-8c08-3b490d278fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_evaluator_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "### **Evaluation Prompt for Research (AI as Judge)**  \n",
    "\n",
    "You are an evaluator assessing the relevance and adequacy of research results based on a defined **story request** \n",
    "and a **suggested agenda**. \n",
    "\n",
    "Your goal is to determine whether the provided research aligns with the requested topic and provides useful, structured, and relevant information.  \n",
    "\n",
    "Here is the evaluation data:\n",
    "[BEGIN DATA]  \n",
    "************  \n",
    "<Request>\n",
    "{input}\n",
    "</Request>\n",
    "************  \n",
    "<Research>\n",
    "{response}\n",
    "</Research>\n",
    "************\n",
    "[END DATA]  \n",
    "\n",
    "#### **Evaluation Process**  \n",
    "1. **Relevance to Request**  \n",
    "   - Does the research directly address the requested chapter and its covered topics?  \n",
    "   - Does it stay within the intended scope without deviating into unrelated areas?  \n",
    "\n",
    "2. **Alignment with Proposed Planning**  \n",
    "   - Does the research sufficiently cover the key points outlined in the planning?  \n",
    "   - Are the topics appropriately developed to provide meaningful insights?  \n",
    "\n",
    "3. **Usefulness & Informational Value**  \n",
    "   - Is the research **clear, structured, and informative**?  \n",
    "   - Does it provide **credible information** (facts, explanations, or sources where applicable)?  \n",
    "   - Can the content be **directly used** for the requested video script without requiring excessive modifications?  \n",
    "\n",
    "#### **Evaluation Criteria (Score 0-10)**  \n",
    "- **8-10**: The research is highly relevant, well-structured, and directly usable for the script.  \n",
    "- **6-8**: Mostly aligned but may lack minor details or refinement.  \n",
    "- **4-6**: Partially aligned, missing key elements or requiring significant rework.  \n",
    "- **2-4**: Misaligned with the request, lacks important aspects, or includes off-topic content.  \n",
    "- **0-2**: Irrelevant or not useful for the intended purpose.  \n",
    "\n",
    "#### **Response Format:**  \n",
    "**Grade:** <ACCEPTABLE or UNACCEPTABLE>  \n",
    "**Score:** <0-10>  \n",
    "**Comment:** <Brief justification for the score, highlighting any gaps or misalignment>  \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107e3748-e1f6-4543-b987-bcb1486fa727",
   "metadata": {},
   "source": [
    "LLM as judge is very easy to setup with LC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd504f23-c42b-4699-a66c-d3773947baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScriptEvaluatorFeedback(TypedDict):\n",
    "    Grade: Literal['ACCEPTABLE', 'UNACCEPTABLE']\n",
    "    Score: int\n",
    "    Comment: str\n",
    "\n",
    "research_evaluator = research_evaluator_prompt | llm.with_structured_output(ScriptEvaluatorFeedback)\n",
    "\n",
    "\n",
    "def valid_research(input: str, output: str) -> ScriptEvaluatorFeedback:\n",
    "  \"\"\"Use an LLM to judge if the research is consistent.\"\"\"\n",
    "\n",
    "  res = research_evaluator.invoke(input={\"input\": input, \"response\": output})\n",
    "  return res\n",
    "\n",
    "\n",
    "def test_researcher(agent, input):\n",
    "\n",
    "    output = agent.invoke(input={\"messages\": input})\n",
    "\n",
    "    res = valid_research(input, output)\n",
    "\n",
    "    assert res[\"Grade\"], \"Acceptable\"\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b3d93a-ebdf-4bbe-b2f9-51e82f2c93e1",
   "metadata": {},
   "source": [
    "I advice you to go further with LangSmith on [LLM as Judge](https://docs.smith.langchain.com/evaluation/how_to_guides/llm_as_judge) with  dataset and evaluator and include it in your test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fdc968-481f-4bd4-8674-ed21a45b8c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_researcher(researcher, input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215c1f3c-fb9d-4a0d-80d5-9fda0748da26",
   "metadata": {},
   "source": [
    "Result will be probably evaluated as 'UNACCEPTABLE'.  \n",
    "\n",
    "There are several strategies to improve that, like performing external search as stated before or operate chapter per chapter. \n",
    "We will cover the 2nd stategy later.\n",
    "\n",
    "Again this is not very important at this stage, we want to keep research agent simple.\n",
    "\n",
    "For our demo purpose, **Mistral Small 3** has sufficient 'world knowlegde' to produce **good enough** research. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e004233-850e-42de-857e-ad616b6400c7",
   "metadata": {},
   "source": [
    "### Good Practice #2: Prompt-Oriented Architecture\n",
    "\n",
    "In GenAI app development, it's a best practice to decouple business logic from prompt engineering since prompts and system instructions follow a distinct lifecycle from the application's core logic. \n",
    "\n",
    "By treating prompts as modular and reusable assets—akin to data-driven prompting or prompt templates—developers can iterate independently, facilitate A/B testing, and streamline integration with LLM orchestration frameworks like LangChain or LlamaIndex. \n",
    "\n",
    "Tools such as [LangSmith](https://smith.langchain.com/) Prompt Hub enable prompt versioning and evaluation, ensuring optimal performance without entangling prompt design with backend workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d62f093-2cf4-447e-bdb8-3aa7f927299d",
   "metadata": {},
   "source": [
    "So next, we'll declare the 'scriptwriter' prompt directly in prompt hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19531620-0c45-42c4-8538-4fcb99e36d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langsmith.utils import LangSmithConflictError\n",
    "\n",
    "writer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are the **Scriptwriter** in a team responsible for scriptwriting YouTube videos.\n",
    "\n",
    "            Your job is to:\n",
    "            - Write or improve a video script based on the agenda and information given.\n",
    "            - Make changes based on feedback to improve your script.\n",
    "            - Only use the information provided; do not do additional research.\n",
    "            \n",
    "            ### How to Format Your Output\n",
    "            1. Put the **full script** in the `chapter` section. Write it as plain text without any formatting.\n",
    "            2. Put any notes, responses to feedback, or extra suggestions in the `comment` section. Write these as plain text, like a conversation.\n",
    "            \n",
    "            ### Important Points\n",
    "            - Do not use structured formatting (like JSON or XML) in the `comment` section.\n",
    "            - If you need more information, say so in the `comment` section.\n",
    "            - Make sure the `chapter` text is clear and complete without relying on formatting.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "# langsmith create an error if prompt's content does not change. So we catch the error. \n",
    "try:\n",
    "    hub.push(repo_full_name=\"tuto-video-script-writer-prompt\", object=writer_prompt, new_repo_is_public=False)\n",
    "except LangSmithConflictError as e:\n",
    "    print(f\"Prompt has not changed.'{e}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dca5664-585a-4c7c-8cf3-09e083cb64c1",
   "metadata": {},
   "source": [
    "Then, we will use the writer prompt to create the writer agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4591e658-8f9f-442e-b523-888c81131a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# WRITER     #\n",
    "##############\n",
    "\n",
    "class Draft(TypedDict):\n",
    "    script: str\n",
    "    comment: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee0ea5d-1400-4ac5-99ef-2349ca421368",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_prompt = hub.pull(\"tuto-video-script-writer-prompt\")\n",
    "writer = writer_prompt | llm.with_structured_output(Draft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47c96f1-996b-47a2-b01b-fa538014c785",
   "metadata": {},
   "source": [
    "We can do the same with the previously declared researcher prompt.\n",
    "\n",
    "```python\n",
    "try:\n",
    "    hub.push(repo_full_name=\"tuto-video-script-researcher-prompt\", object=researcher_prompt, new_repo_is_public=False)\n",
    "except LangSmithConflictError as e:\n",
    "    print(f\"Prompt has not changed.'{e}'\")\n",
    "\n",
    "\n",
    "researcher_prompt = hub.pull(\"tuto-video-script-researcher-prompt\")\n",
    "researcher = researcher_prompt | llm.with_structured_output(Research)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5309673b-527f-4306-a861-515876a154f9",
   "metadata": {},
   "source": [
    "If you don't want to use Prompt hub yet, use this script to declare writer agent\n",
    "\n",
    "```python\n",
    "writer = writer_prompt | llm.with_structured_output(Draft)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afad01d-113d-47cb-95c2-2e054a917f76",
   "metadata": {},
   "source": [
    "Let's test the 'writer agent'.\n",
    "\n",
    "First, we will format a message for the writer based on the result of research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d895f-c483-40af-b3e9-d2552b33db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_res_comment = researcher_res.get('comment', 'No comment provided.')\n",
    "researcher_res_content = researcher_res['research']\n",
    "research_message_content = (f\"# Research \"\n",
    "                            f\"\\n\\n{researcher_res_content}\"\n",
    "                            f\"\\n\\n-----\\n\\n# Researcher Comment\"\n",
    "                            f\"\\n\\n{researcher_res_comment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf06fce4-cacf-42ee-b536-54745c5c1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_message_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f567b85b-1993-4d37-8400-1c16f01a80d0",
   "metadata": {},
   "source": [
    "Next, we prepare messages input for the writer. We take previous conversation on which we append research result and writer instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1352437-3088-42ad-be4d-7393e24da8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_input = input + [(\"assistant\", research_message_content), \n",
    "          (\"human\", \"Write the script for the video using agenda and research.\") ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71aff4-47b2-4393-b261-6871957eb6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_res = writer.invoke(input={\"messages\": writer_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cdd666-db1a-42c6-9342-cc459b6d1375",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94187925-80d3-4c11-90fd-fb5607e3eca9",
   "metadata": {},
   "source": [
    "# Chapter 3: Creating a Minimal Skeleton of our Agentic Workflow (Planner + Researcher +Writer)\n",
    "\n",
    "Defining an Initial Graph\n",
    "\n",
    "To start, we create a simple workflow with two agents:\n",
    "\n",
    "1. **Planner**: Determines the script structure (agenda, key topic, brief).\n",
    "2. **Researcher**: Generates research based on the agenda.\n",
    "3. **Writer**: Generates the script based on the agenda + research.\n",
    "\n",
    "In LangGraph, an agentic workflow is describe with a Graph representation. So will have to define a Graph, Node and edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df09456-d2ba-4f94-b464-62ef3dd7d765",
   "metadata": {},
   "source": [
    "Let's now create the planning step. This will be used by the team to guide during their script writing  process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfe115b-d298-45bf-b631-2b4707d8448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chapter(TypedDict):\n",
    "    title: str\n",
    "    covered_topics: List[str]\n",
    "\n",
    "\n",
    "class Planning(TypedDict):\n",
    "    topic: str\n",
    "    plan: List[Chapter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe8674b-7874-4659-8e6c-73ae236f7786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b82196e-945f-4ffb-b6da-f148f63a8072",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are the 'producer' in a team responsible for scriptwriting YouTube videos.\\n\\n\"\n",
    "            \"Your responsibilities:\\n\"\n",
    "            \"- Plan the video agenda: \\n\"\n",
    "            \"Define for each section:\"\n",
    "            \" - Title [words count]\\n\"\n",
    "            \" - covered topics (max 3)\\n\"\n",
    "            \"- Decide which team members should act 'next' or provide 'approval' for the script revision to move forward.\\n\"\n",
    "            \"You ensure that the process is efficient by limiting iteration or superfluous revision.\\n\"\n",
    "            \"The video must follow this template :\\n\"\n",
    "            \"- Section 1: Video hook and intro\\n\"\n",
    "            \"- Section 2: Body, main content \\n\"\n",
    "            \"- Section 3: CTA (call to action) and Conclusion\\n\"\n",
    "            \"\\n\\n\"\n",
    "            \"You DO NOT write script.\\n\"\n",
    "            \"You DO NOT make research.\"\n",
    "            \"You DO NOT review.\\n\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "planner = producer_prompt | llm.with_structured_output(Planning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf2245-97ed-46ae-aee6-2a049a747d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_prompt = PromptTemplate.from_template(\n",
    "    \"Elaborate the plan of the video script. \\n\"\n",
    "    \"Define for each chapter:\\n\"\n",
    "    \" - Chapter 'Title' (including words count directive for the chapter in format '[X words]')\\n\"\n",
    "    \" - Covered topics (max 3 per chapter) with specific and actionable direction.\\n\"\n",
    "    \" - Brief for the chapter explaining where you want to go.\\n\"\n",
    "    \"You provide information that guide your team to deliver the story you envision.\\n\"\n",
    "    \"\\n\\n\"\n",
    "    \"The video plan must follow this structure :\\n\"\n",
    "    \"- 'Opening Section': contains video hook and introduction.\\n\"\n",
    "    \"- 'Main Section': 'Body' of the script where you develop the X chapters.\\n\"\n",
    "    \"- 'Closing Section': contains the CTA (call to action) and a brief conclusion.\\n\"\n",
    "    \"\\n\\n\"\n",
    "    \"Opening and Closing section does not count as 'user chapters'. \"\n",
    "    \"If user ask for 3 chapters, you must plan for 5 (1: Hook+Introduction, 2,3,4: user chapters, 5: CTA+Conclusion)\"\n",
    ")\n",
    "try:\n",
    "    hub.push(repo_full_name=\"tuto-video-script-planner-prompt\", object=planner_prompt, new_repo_is_public=False)\n",
    "except LangSmithConflictError as e:\n",
    "    print(f\"Prompt has not changed.'{e}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f1bea1-3648-4f58-99c0-493995c681de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import  BaseMessage\n",
    "\n",
    "class VideoScriptState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    chapters: List[Chapter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a983b-a164-4e3c-b0e5-57b9643c69b6",
   "metadata": {},
   "source": [
    "In LangGraph, the Graph's *'State'* is a **shared data structure** that represents the current snapshot of your application. It can be any Python type, but is typically a TypedDict or Pydantic BaseModel.\n",
    "\n",
    "It is what will collect the messages produced by each agent within the workflow. But you can use it to share any information each component in your graph need to collaborate.\n",
    "\n",
    "Here, we will add the chapter generated by the 'planner_node' that will be used by 'researcher' and 'writer'.\n",
    "\n",
    "Why that? We want to handle at a granular level what each node works on. We cannot only rely on the conversation as it may become very long and agent could start to be confused. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2614b5-e648-450a-8ae8-6b8f6f52e712",
   "metadata": {},
   "source": [
    "Let's define a node for Planner, researcher and writer. The planner node is the 'host/producer' agent with a specific prompt to create the agenda.\n",
    "\n",
    "We parse the output of **'planner'** agent to add its content directly in the **'VideoStateGraph'** in **'chapter'** field.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edb90f6-4057-479d-890f-e26e8e370612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# TOOLING\n",
    "#####################\n",
    "\n",
    "def _format_chapters(chapters):\n",
    "    formatted_chapters = \"\"\n",
    "    for chapter in chapters:\n",
    "        formatted_chapters += f\"{chapter['title']}:\\n\"\n",
    "        if 'chapter_brief' in chapter:\n",
    "            formatted_chapters += f\"  - Brief: {chapter['chapter_brief']}\\n\"\n",
    "        formatted_chapters += \"  - Covered Topics:\\n\"\n",
    "        for topic in chapter['covered_topics']:\n",
    "            formatted_chapters += f\"    - {topic}\\n\"\n",
    "        formatted_chapters += \"\\n\"\n",
    "    return formatted_chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ec29b5-3bfb-4e40-bc4b-090b2c0dba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner_node(state: VideoScriptState) -> VideoScriptState:\n",
    "    \"\"\"\n",
    "    The Host/Producer sets the plan (how many chapters, the overall direction).\n",
    "    In a real scenario, you'd call host_producer_prompt with the user request to produce an agenda.\n",
    "    We'll simulate it here.\n",
    "    \"\"\"\n",
    "    # If not already done, let's define chapters in the conversation or from user input\n",
    "    # Example simulation: The user wants a 3-chapter video, so we store that:\n",
    "    if not state.get(\"chapters\"):\n",
    "\n",
    "        planner_prompt = hub.pull(\"tuto-video-script-planner-prompt\")\n",
    "        message_content = planner_prompt.format()\n",
    "        messages = state[\"messages\"] + [HumanMessage(content=message_content, name=\"user\")]\n",
    "        res = planner.invoke(input={\"messages\": messages})\n",
    "        chapters = res['plan']\n",
    "        state[\"chapters\"] = chapters\n",
    "        formatted_chapters = _format_chapters(chapters)\n",
    "        producer_message = (f\"Here's a suggested agenda for your video.\"\n",
    "                            f\"\\n\\n{formatted_chapters}\")\n",
    "        host_message = AIMessage(content=producer_message, name=\"host-producer\")\n",
    "        state[\"messages\"].append(host_message)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a52ca-0cbc-4f68-a26a-51e2cdd5f9f7",
   "metadata": {},
   "source": [
    "### Command: A new tool for building multi-agent architectures in LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e3244-9c71-499f-9973-6d182247045b",
   "metadata": {},
   "source": [
    "For the next node, we will use a new addition to LangGraph arsenal : *'Command'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53710d95-0f21-4cb7-84ec-95c25622c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3335e7d9-c94f-41a3-b6c7-1ec11a77096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def researcher_node(state: VideoScriptState) -> Command[Literal[\"writer\"]]:\n",
    "    \"\"\"\n",
    "    The Researcher provides factual data/ideas for the current chapter.\n",
    "    For demonstration, we just append a dummy 'AIMessage' with bullet points.\n",
    "    \"\"\"\n",
    "    chapters = state[\"chapters\"]\n",
    "    message_content = f\"Provide research for the video covering the key topics of agenda.\"\n",
    "    human_message = HumanMessage(content=message_content, name=\"user\")\n",
    "    messages = state[\"messages\"] + [human_message]\n",
    "\n",
    "    res = researcher.invoke(input={\"messages\": messages})\n",
    "\n",
    "    research_response_comment = res.get('comment', 'No comment provided.')\n",
    "    research_chapter_content = res['research']\n",
    "    research_message_content = (f\"# Research\"\n",
    "                                f\"\\n\\n{research_chapter_content}\"\n",
    "                                f\"\\n\\n-----\\n\\n#Comment\"\n",
    "                                f\"\\n\\n{research_response_comment}\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [AIMessage(content=research_message_content, name=\"researcher\")],\n",
    "        },\n",
    "        goto=\"writer\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006bf4ac-949b-4681-849b-001b795f5fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writer_node(state: VideoScriptState) -> Command[Literal[\"__end__\"]]:\n",
    "    \"\"\"\n",
    "    The Writer composes or updates the script for the current chapter using the research input.\n",
    "    \"\"\"\n",
    "    chapters = state[\"chapters\"]\n",
    "    message_content = f\"Write the script using agenda and research.\"\n",
    "    human_message = HumanMessage(content=message_content, name=\"user\")\n",
    "    messages = state[\"messages\"] + [human_message]\n",
    "\n",
    "    res = writer.invoke(input={\"messages\": messages})\n",
    "\n",
    "    # Check if 'comment' is in the response\n",
    "    writer_script_content = res['script']\n",
    "    writer_response_comment = res.get('comment', 'No comment provided.')\n",
    "\n",
    "    writer_message_content = (f\"# Script\"\n",
    "                              f\"\\n\\n{writer_script_content}\\n\\n-----\"\n",
    "                              f\"\\n\\n# Writer Comment\"\n",
    "                              f\"\\n\\n{writer_response_comment}\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [AIMessage(content=writer_message_content, name=\"writer\")],\n",
    "        },\n",
    "        goto=\"__end__\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d8a04e-0e13-46d4-b2c7-1dfb3b4459f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "workflow = StateGraph(VideoScriptState)\n",
    "workflow.add_node(\"planning\", planner_node)\n",
    "workflow.add_node(\"researcher\", researcher_node)\n",
    "workflow.add_node(\"writer\", writer_node)\n",
    "workflow.add_edge(START, \"planning\")\n",
    "workflow.add_edge(\"planning\", \"researcher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee04b80-a75d-46c8-87c3-4ad7ffa6e059",
   "metadata": {},
   "source": [
    "Of course, LangGraph need to store the state of the graph somewhere. It use Memory for that. For real use case,\n",
    "you must use persistant memory but for this demo we will use MemorySaver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1bab5d-0c78-4c7b-9b4b-00059971f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6742e456-35ed-41aa-8d78-5ccbc3b9baf6",
   "metadata": {},
   "source": [
    "And at the end, we compile the Graph. LangGraph will check its consistency so you can have error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead86184-e6fb-4540-bf13-fbccdebe008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_script_app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0b74f0-20df-4221-b280-fc88121fa1e7",
   "metadata": {},
   "source": [
    "We can see the 2 approaches here:\n",
    "\n",
    "- **'planning_node'** function return an updated *'StateGraph'* and the *'edge'* between **'planning_node'** and **'writer_node'** is declare at graph level with *'add_edge'* method.\n",
    "- **'researcher_node'** and **'writer_node'** use *'Command'* and its attribute *'goto'* to create the *'edge'* between them. It is also in the signature of the function (return). Command is an important addition to LangGraph to allow dynamic workflow. Change on *'StateGraph'* is transfer via the *'update*' parameter. This allow *handoff* between agents in the graph.\n",
    "\n",
    "If you prefer the first method, you can use 'add_conditional_edge' method of stategraph for decision making. Take care, you cannot combined both approach (ie. a node that return a Command and a conditional_edge on the graph).\n",
    "\n",
    "Let's see what our graph looks like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf8d21-2d16-48b6-bd73-b8d29f970be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(video_script_app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa1df65-27c9-4458-b8a7-aaa187a38526",
   "metadata": {},
   "source": [
    "We have a linear process '__start__' --> 'planning' --> 'researcher' --> 'writer' --> '__end__' which starts to look like something we could do in real-life. You see that the edges are not the same (continuous versus dotted line) showing the two approach.\n",
    "\n",
    "So we are not in an agentic workflow yet as each step is know and no agent decide what will come next. But we have already moved away from le llm-chain paradigm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f802bb-9c44-4753-88d6-439d550fb613",
   "metadata": {},
   "source": [
    "Let's run the graph now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b2c33-d7d4-44d0-822e-4cd9799dd5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\"I'd like a 2-chapter video of 2 minutes of 450 words on 'AI Won't Take Your Jobs. Those Who Use AI Will!'\")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "example_input = {\n",
    "    \"messages\": [(\"human\", prompt)],\n",
    "}\n",
    "\n",
    "# Collect all steps from the astream generator\n",
    "steps = [step for step in video_script_app.stream(example_input, config=config, stream_mode=\"values\")]\n",
    "\n",
    "# Access the last step\n",
    "last_step = steps[-1]\n",
    "\n",
    "print(f\"Directive: '{prompt}'\")\n",
    "\n",
    "# Print the last message of the last step\n",
    "last_message = last_step[\"messages\"][-1]\n",
    "\n",
    "output = last_message.pretty_repr()\n",
    "print(f\"Result: '{output}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6be045-21dd-4fa0-b6dd-0ebb038d07a8",
   "metadata": {},
   "source": [
    "What's important here is ```config = {\"configurable\": {\"thread_id\": \"1\"}}```\n",
    "\n",
    "You have to define a **'thread_id'** for each user. This is mandatory because StateGraph is statefull. You remember the 'MemorySaver' we have added when we compile the graph. So you have to identify the user uniquely.\n",
    "\n",
    "LangChain use **'session_id'** to handle conversation history per user. So you'll have to initialize both value if you are using advanced chain like *'RunnableWithMessageHistory'*. \n",
    "\n",
    "So if you are already using LC, take care: LC and LG does not use the same *keyword* for memory management.\n",
    "\n",
    "In this notebook, we can simply use 1 as value but for real application you will probably have a code like:\n",
    "\n",
    "```python\n",
    "import uuid\n",
    "\n",
    "thread_id = config.configurable.get(\"thread_id\") if config and hasattr(config, 'configurable') else str(uuid.uuid4())\n",
    "```\n",
    "\n",
    "uuid helps to generate unique id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239587af-1836-4814-94b4-dee4be5a0612",
   "metadata": {},
   "source": [
    "2nd interesting things is that langgraph work per step (and handle everything smoothly for you). It will orchestrate the call between all agent. We won't go into the detail of what is going while langgraph is executing the process. Here, we just retrieve the last step and display the last message.\n",
    "\n",
    "StateGraph is also a runnable (like LangChain chain) so you have all the nice feature with async calling, streaming, batching etc. You also have access granularly to all events during execution to display progress to user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4d7bb3-e187-4cd4-b841-d0fdec99ab76",
   "metadata": {},
   "source": [
    "## Chapter 7: Agentic Evaluation and Simulation\n",
    "\n",
    "Like agent, you have to test you agentic worklow. Here we will use the same strategy has research but for final script. For conversational agent, you will use a [Simulator agent](https://langchain-ai.github.io/langgraph/tutorials/chatbot-simulation-evaluation/agent-simulation-evaluation/) that will replace the human interaction. As we have a fully automatized process, we just evaluate the final results. Also I recommend to set up more advanced test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4d5d9f-1c71-4f37-b187-88831e1bfb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_evaluator_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are evaluating a submitted script based on the given request. \n",
    "\n",
    "Here is the evaluation data:\n",
    "[BEGIN DATA]  \n",
    "************  \n",
    "<Request>\n",
    "{input}\n",
    "</Request>\n",
    "************  \n",
    "<SubmittedScript>\n",
    "{response}\n",
    "</SubmittedScript>\n",
    "************\n",
    "[END DATA]  \n",
    "\n",
    "Compare the submitted script with the request.  \n",
    "Ignore differences in style, minor phrasing, or wording variations.  \n",
    "\n",
    "Assess alignment based on:  \n",
    "- **Structure**: Does it follow a logical **chapitrage** (proposed agenda)?  \n",
    "- **Angle**: Does the story perspective fit the topic?  \n",
    "- **Length & Duration**: Is it reasonably aligned with expectations?  \n",
    "- **Language**: Does the script is in the expected language (same as request if user not specify)?  \n",
    "- **Quality**: Is it coherent, engaging, and suitable for a YouTube AI audience?  \n",
    "\n",
    "**Grade the result:**  \n",
    "- **8 to 10**: Fully meets the request across all aspects.  \n",
    "- **6 to 8**: Mostly aligned, with minor gaps.  \n",
    "- **4 to 6**: Partially aligned, missing key aspects.  \n",
    "- **2 to 4**: Significant misalignment with the request.  \n",
    "- **0 to 2**: Off-topic or completely missing expectations.  \n",
    "If the submission is entirely missing or contains no meaningful content (ex: None), assign a score of 0.\n",
    "The script is **ACCEPTABLE** if the score is above 6. It is **UNACCEPTABLE** if the score is below 6.  \n",
    "\n",
    "**Answer format:**  \n",
    "Grade: <ACCEPTABLE or UNACCEPTABLE>  \n",
    "Score: <grade from 0 to 10>\"**  \n",
    "Comment: <Brief justification for the score, highlighting any gaps or misalignment>  \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a76a04-69dd-4799-8c53-cc1f7f77bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "script_evaluator = script_evaluator_prompt | llm.with_structured_output(ScriptEvaluatorFeedback)\n",
    "\n",
    "\n",
    "def valid_script(input: str, output: str) -> ScriptEvaluatorFeedback:\n",
    "  \"\"\"Use an LLM to judge if the script is consistent.\"\"\"\n",
    "\n",
    "  res = script_evaluator.invoke(input={\"input\": input, \"response\": output})\n",
    "  return res\n",
    "\n",
    "\n",
    "def test_script(agent, input):\n",
    "\n",
    "    thread_id = config.configurable.get(\"thread_id\") if config and hasattr(config, 'configurable') else str(\n",
    "        uuid.uuid4())\n",
    "\n",
    "    effective_config = {\"recursion_limit\": 99, \"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "    input_data = {'messages': [HumanMessage(content=input)],}\n",
    "\n",
    "    steps = [step for step in agent.stream(input=input_data, config=effective_config, stream_mode=\"values\")]\n",
    "\n",
    "    # Access the last step\n",
    "    last_step = steps[-1]\n",
    "\n",
    "    # Print the last message of the last step\n",
    "    last_message = last_step[\"messages\"][-1]\n",
    "    output = last_message.pretty_repr()\n",
    "\n",
    "    # output = agent.invoke(input={\"messages\": input})\n",
    "\n",
    "    res = valid_script(input, output)\n",
    "\n",
    "    assert res[\"Grade\"], \"Acceptable\"\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabbd31e-03ac-482d-abc0-9f12c715578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_script(video_script_app, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222efde-1dea-4a0a-ad08-cc9e87c18d11",
   "metadata": {},
   "source": [
    "This is basic testing but it is very simple to implement and as your workflow start to complexify, you must have a robust testing strategy in place from the beggining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e613bd-b9f8-4529-935c-c2f8e65a26bb",
   "metadata": {},
   "source": [
    "If you look carefully at the test_script function, you'll notice that I've added a **\"recursion_limit\"** parameter to the configurable.\n",
    "This is very important as from now we will add 'branch' and 'loop' in our graph and we doesn't not want our workflow go into infinite loop (as the logic and decision will be handled by autonomous agents). So **'recursion_limit'** will avoid our AI Agent go crazy and stop before consuming all our credits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9610eaba-4472-4d92-a036-8d4e3119f01c",
   "metadata": {},
   "source": [
    "# Chapter 8: Supervisor node\n",
    "\n",
    "First, we will add a new member in the script writing team: **'reviewer'**.\n",
    "\n",
    "Reviewer will be in charge to check the quality of the research and the script and give advice for enhance. He will advice if the work must be done by research if more input is needed or writer if only style or structure revision is required. He will also 'approved' the script if it is ok. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5630cb-0c24-42ab-b20c-01f4e46440b9",
   "metadata": {},
   "source": [
    "But for good measure, we will redeclare import in one cell so we won't have to search for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1a43b1-699a-41a2-b4f1-e3e913b555a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redeclaring import here to avoir searching in different cells.\n",
    "from typing import TypedDict, Literal, Annotated, List,  Tuple\n",
    "\n",
    "from langgraph.types import Command\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import  BaseMessage\n",
    "\n",
    "from langchain import hub\n",
    "from langsmith.utils import LangSmithConflictError\n",
    "\n",
    "import operator\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db948c2-9311-4113-8751-6e97f626e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewFeedback(TypedDict):\n",
    "    GoodPoints: str\n",
    "    MissingOrNeedsResearch: str\n",
    "    SuperfluousContent: str\n",
    "    StyleRefinement: str\n",
    "    NextNode: Literal['researcher', 'writer', 'approved']\n",
    "\n",
    "review_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are the `Reviewer` in a team responsible for scriptwriting YouTube videos.\\n\\n\"\n",
    "            \"\"\"Based solely on the proposed key topics and brief from the agenda and writing guidelines,\n",
    "            your task is to evaluate the script draft and provide concise and structured feedback in four parts:\n",
    "\n",
    "            1. **GoodPoints**: List the positive aspects that should be retained.\n",
    "            2. **MissingOrNeedsResearch**: Specify missing information or areas that require more research.\n",
    "            3. **SuperfluousContent**: Identify anything unnecessary or off-topic in the chapter.\n",
    "            4. **StyleRefinement**: Major issues with writing guidelines such as word counts per chapter or repetition.\n",
    "            5. **NextNode**: Indicate the next action by choosing one of:\n",
    "               - 'approved': If no major revisions or research are necessary.\n",
    "               - 'writer': If Superfluous Content or Style Refinement BUT NO NEW CONTENT.\n",
    "               - 'research': If Missing Or Needs Research to address gaps or improve accuracy from the agenda.\n",
    "\n",
    "            ---\n",
    "\n",
    "            ### **Decision-Making Guidance for NextNode**:\n",
    "            1. Choose **'approved'** (default) if issues are minor or stylistic.\n",
    "            2. Choose **'writer'** if structural or stylistic improvements are required AND NO NEW content is required.\n",
    "            3. Choose **'research'** if missing content.\n",
    "            **IMPORTANT**: 'writer' cannot do his own research. Go to 'research' any time new content is necessary.\n",
    "            In case of ambiguity or perplexity, choose 'research'.\n",
    "            ---\n",
    "            \"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reviewer = review_prompt | llm.with_structured_output(ReviewFeedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087723a5-a814-4ac0-a2f8-12738bea546a",
   "metadata": {},
   "source": [
    "Nothing particular to comment here.\n",
    "\n",
    "Let's define the **'reviewer_node'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a908c-3538-460c-9d08-f2bd131fd1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviewer_node(state: VideoScriptState) -> Command[Literal[\"supervisor\"]]:\n",
    "    \"\"\"\n",
    "    The 'Reviewer' agent checks the current draft:\n",
    "      - If acceptable, we finalize the chapter.\n",
    "      - If not acceptable, we request changes => 'draft_node' or 'researcher_node' again.\n",
    "    \"\"\"\n",
    "\n",
    "    human_message = HumanMessage(content=f\"Review the draft of the chapter\", name=\"user\")\n",
    "    messages = state[\"messages\"] + [human_message]\n",
    "\n",
    "    res = reviewer.invoke(input={\"messages\": messages})\n",
    "\n",
    "    reviewer_message_content = (\n",
    "        f\"# Reviewer Feedback\\n\\n\"\n",
    "        f\"Good Points:\\n {res['GoodPoints']}\\n\\n\"\n",
    "        f\"Missing or Needs Research:\\n {res['MissingOrNeedsResearch']}\\n\\n\"\n",
    "        f\"Superfluous Content:\\n {res['SuperfluousContent']}\\n\\n\"\n",
    "        f\"Style Refinement:\\n {res['StyleRefinement']}\\n\\n\"\n",
    "        f\"next: {res['NextNode']}\\n\\n\"\n",
    "    )\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [AIMessage(content=reviewer_message_content, name=\"reviewer\")],\n",
    "            \"next\": res[\"NextNode\"],\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19a7900-59d4-4d29-9fb2-e405763e3851",
   "metadata": {},
   "source": [
    "'Reviewer' gives feedback on the quality of the script revision (good points) to keep it and what is missing or need to be change.\n",
    "\n",
    "We have also ask reviewer to give what he estimates to be the 'best' next node that the supervisor should redirect or if he approves the last iteration of the script. For example, we only need style revision, no need to do new research. But if content is missing, we should look for it with the research agent.\n",
    "\n",
    "In real-case scenario, you will have to give 'Guidelines' to each agent to ensure a coherency in style/tone/structure, etc... and avoid infinite revision.\n",
    "\n",
    "The next agent will be pass through the State of the graph so we add the field **'next'** in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84f63d8-a405-45eb-869b-ef49111ced61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoScriptState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    chapters: List[Chapter]\n",
    "    next: Literal['researcher', 'writer', 'approved']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b578fdeb-8070-492a-aa3a-56e6698c2c07",
   "metadata": {},
   "source": [
    "Now we will create a supervisor node that will orchestate the job between each agent chapter per chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69f9eef-4d02-464c-898f-c604969b1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "members = [\"researcher\", \"writer\"]\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = members + [END]\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    f\" following workers: {members}. Given the initial user request and advice from reviewer,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and comments. When finished,\"\n",
    "    \" respond with 'approved'.\"\n",
    ")\n",
    "\n",
    "\n",
    "class Router(TypedDict):\n",
    "    \"\"\"Worker to route to next. If no workers needed, route to 'approved'.\"\"\"\n",
    "    next: Literal['researcher', 'writer', 'approved']\n",
    "\n",
    "\n",
    "\n",
    "def supervisor_node(state: VideoScriptState) -> Command[Literal[*options]]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + state[\"messages\"]\n",
    "    host_message = HumanMessage(content=\"What to do next?\", name=\"host-producer\")\n",
    "    messages += [host_message]\n",
    "    response = llm.with_structured_output(Router).invoke(messages)\n",
    "    goto = response[\"next\"]\n",
    "    if goto == \"approved\":\n",
    "        goto = END\n",
    "\n",
    "    return Command(goto=goto, update={\"next\": \"\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c15aa26-f5b7-43d5-a32f-8b09ea2d227f",
   "metadata": {},
   "source": [
    "This is a basic version of supervisor. We'll update it later to handle chapter-based execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e09c0a1-c0e8-4637-b79b-f6d57521ae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(VideoScriptState)\n",
    "workflow.add_node(\"planning\", planner_node)\n",
    "workflow.add_node(\"researcher\", researcher_node)\n",
    "workflow.add_node(\"writer\", writer_node)\n",
    "workflow.add_node(\"reviewer\", reviewer_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_node)\n",
    "workflow.add_edge(START, \"planning\")\n",
    "workflow.add_edge(\"planning\", \"supervisor\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "video_script_workflow = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4eb57-7f69-4f76-a1ce-36fccb8ac170",
   "metadata": {},
   "source": [
    "Let's display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a69a8-bf52-4bd0-af02-5cd09cf46d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(video_script_workflow.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cfb5aa-4d61-4b4b-aa0b-f05d35dfe861",
   "metadata": {},
   "source": [
    "We won't try to execute it because reviewer won't be happy with research and script and will certainly go into an infinite revision cycle. So we need to split the job into simpler task and manage task iteration. We will work chapter by chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb17bfc-4b54-4265-8800-2ab5fedd9341",
   "metadata": {},
   "source": [
    "### Updating the Supervisor to Work Chapter by Chapter with Max Iteration\n",
    "To implement chapter-by-chapter execution and max iteration per chapter, we need to modify VideoScriptState to track:\n",
    "\n",
    "1. The current chapter index (which chapter we are working on).\n",
    "1. A counter for how many times a chapter has been revised.\n",
    "1. Ensure the user message explicitly refers to the chapter being worked on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f46444-c1f0-487e-9cde-41c5284fd007",
   "metadata": {},
   "source": [
    "### Updated supervisor_node to Handle Chapter-Based Execution\n",
    "#### Logic Adjustments\n",
    "\n",
    "- Check if all chapters are completed → if yes, finalize the script.\n",
    "- Track chapter iterations:\n",
    "    - If current_chapter_iteration >= MAX_REVISION, move to the next chapter.\n",
    "    - Else, draft or revise the current chapter.\n",
    "\n",
    "- Route based on agent feedback:\n",
    "   - If research is weak → loop back to researcher\n",
    "   - If writing needs improvement → loop back to writer\n",
    "   - If all conditions are met → move to the next chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f72f1e8-e6a7-4825-a513-5f3f411e5a92",
   "metadata": {},
   "source": [
    "#### Key Modifications to VideoScriptState\n",
    "\n",
    "We'll extend the VideoScriptState definition to include:\n",
    "\n",
    "- ```current_chapter_index```: Tracks which chapter is being processed.\n",
    "- ```current_chapter_iteration```: Tracks how many times the current chapter has been iterated.\n",
    "- ```final_script```: Stores the fully approved script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa33058d-a70d-45cf-bc27-7e27075310fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoScriptState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    chapters: List[Chapter]\n",
    "    current_chapter_index: int\n",
    "    current_chapter_iteration: int\n",
    "    final_script: str\n",
    "    next: Literal['researcher', 'writer', 'approved']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8590234f-148f-474f-8ed4-daef98528d7c",
   "metadata": {},
   "source": [
    "We add a finalization function:\n",
    "\n",
    "- Ensures all chapters are processed before finalizing.\n",
    "- Appends each chapter to the final_script only when it is validated.\n",
    "- Resets relevant state values after finalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e83644-4bc4-4664-85ac-aaa0ac2b9f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_REVISION = 1  # Maximum revision attempts per chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab42d6e-27c9-4ce0-bde8-02e519127d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor = producer_prompt | llm.with_structured_output(Router)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d430d7-b49d-4533-b1bf-3548205c4b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_script(state: VideoScriptState) -> str:\n",
    "    return (\n",
    "        f\"# FINAL SCRIPT\\n\\n{state['final_script']}\\n\\n### COMMENT\\n\\n\"\n",
    "        \"This script has been fully processed and validated.\"\n",
    "    )\n",
    "\n",
    "def append_chapter(state: VideoScriptState):\n",
    "    current_chapter = state[\"current_chapter_index\"]\n",
    "    # previous message is from reviewer, so go back to writer message in conversation\n",
    "    chapter_content = state[\"messages\"][-2].content if state[\"messages\"] else \"\"\n",
    "    \n",
    "    state[\"final_script\"] += (\n",
    "        f\"\\n\\n## CHAPTER {current_chapter + 1}\"\n",
    "        f\"\\n\\n{chapter_content}\"\n",
    "    )\n",
    "\n",
    "def process_finalization(state: VideoScriptState) -> Command[Literal[END, \"researcher\"]]:\n",
    "    \"\"\"\n",
    "    Manage moving to the next chapter or finalize the script.\n",
    "    \"\"\"\n",
    "    current_chapter = state[\"current_chapter_index\"]\n",
    "\n",
    "    append_chapter(state)\n",
    "\n",
    "    current_chapter += 1\n",
    "\n",
    "    if current_chapter >= len(state[\"chapters\"]):\n",
    "        return Command(\n",
    "            update={\n",
    "                \"final_script\": finalize_script(state),\n",
    "                \"messages\": [AIMessage(content=finalize_script(state), name=\"host-producer\")]\n",
    "            },\n",
    "            goto=END,\n",
    "        )\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"current_chapter_index\": current_chapter,\n",
    "            \"current_chapter_iteration\": 0,\n",
    "            \"final_script\": state['final_script'],\n",
    "            \"next\": \"researcher\",\n",
    "            \"messages\": state[\"messages\"] + [\n",
    "                AIMessage(\n",
    "                    content=f\"Draft Chapter {current_chapter + 1}: \"\n",
    "                            f\"'{state['chapters'][current_chapter]['title']}'.\",\n",
    "                    name=\"supervisor\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"researcher\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd1ac80-8b3c-4e37-809d-174946d853c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_node(state: VideoScriptState) -> Command[Literal[*options]]:\n",
    "    \"\"\"\n",
    "    Supervisor navigates the process through the workflow, making decisions on chapters.\n",
    "    \"\"\"\n",
    "    current_chapter = state[\"current_chapter_index\"]\n",
    "    iteration_count = state[\"current_chapter_iteration\"]\n",
    "    next_step = state[\"next\"]\n",
    "\n",
    "    # Finalize if all chapters are completed\n",
    "    if current_chapter >= len(state[\"chapters\"]):\n",
    "        return Command(\n",
    "            update={\n",
    "                \"final_script\": finalize_script(state),\n",
    "                \"messages\": [AIMessage(content=finalize_script(state), name=\"host-producer\")]\n",
    "            },\n",
    "            goto=END,\n",
    "        )\n",
    "\n",
    "    # Use supervisor LLM to decide next step based on last action\n",
    "    messages = state[\"messages\"]\n",
    "    content = (\n",
    "        f\"As the supervisor, decide the next steps between the agents: {members}. \"\n",
    "        f\"Given the current chapter status and revision count ({iteration_count})\"\n",
    "        f\"and last reviewer feedback, decide on the next action.\"\n",
    "    )\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=content, name=\"producer\")]\n",
    "\n",
    "    supervisor_response = supervisor.invoke(input={\"messages\": messages})\n",
    "    next_step = supervisor_response[\"next\"]\n",
    "\n",
    "    # Handle approval or decide on actions\n",
    "    if next_step == \"approved\" or iteration_count >= MAX_REVISION:\n",
    "        return process_finalization(state)\n",
    "\n",
    "    # Prepare message for the next action\n",
    "    # Determine directive type: \"Draft\" for new chapter, \"Revise\" for existing\n",
    "    directive = \"Draft\" if iteration_count == 0 else \"Revise\"\n",
    "    \n",
    "    # Construct supervisor's message for the next agent\n",
    "    next_action_message = f\"{directive} Chapter {current_chapter + 1}: '{state['chapters'][current_chapter]['title']}'.\"\n",
    " \n",
    "    messages = state[\"messages\"] + [AIMessage(content=next_action_message, name=\"supervisor\")]\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"current_chapter_iteration\": iteration_count + 1,\n",
    "            \"next\": next_step,\n",
    "            \"messages\": messages,\n",
    "        },\n",
    "        goto=next_step,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f195a1-eea9-4cd6-9669-1296b225e6ca",
   "metadata": {},
   "source": [
    "We bring here team members to do some adjustement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d6eb20-0915-40b6-bafd-9f46021e17e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def researcher_node(state: VideoScriptState) -> Command[Literal[\"writer\"]]:\n",
    "    \"\"\"\n",
    "    The Researcher provides factual data/ideas for the current chapter.\n",
    "    For demonstration, we just append a dummy 'AIMessage' with bullet points.\n",
    "    \"\"\"\n",
    "    chapter = state[\"chapters\"][state[\"current_chapter_index\"]]\n",
    "    chapter_title = chapter['title']\n",
    "    chapter_detail = _format_chapters([chapter])\n",
    "    message_content = (f\"Provide or enhance research for the chapter '{chapter_title}'\"\n",
    "                       f\" covering the topics on the agenda and advise from reviewer.\"\n",
    "                       f\"\\n\\n{chapter_detail}\")\n",
    "    \n",
    "    human_message = HumanMessage(content=message_content, name=\"user\")\n",
    "    messages = state[\"messages\"] + [human_message]\n",
    "\n",
    "    res = researcher.invoke(input={\"messages\": messages})\n",
    "\n",
    "    research_response_comment = res.get('comment', 'No comment provided.')\n",
    "    research_chapter_content = res['research']\n",
    "    research_message_content = (f\"# Research for '{chapter_title}'\"\n",
    "                                f\"\\n\\n{research_chapter_content}\"\n",
    "                                f\"\\n\\n-----\\n\\n#Comment\"\n",
    "                                f\"\\n\\n{research_response_comment}\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [AIMessage(content=research_message_content, name=\"researcher\")],\n",
    "        },\n",
    "        goto=\"writer\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb84ee-bf23-49a9-acf7-3ad9c36a41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writer_node(state: VideoScriptState) -> Command[Literal[\"reviewer\"]]:\n",
    "    \"\"\"\n",
    "    The Writer composes or updates the script for the current chapter using the research input.\n",
    "    \"\"\"\n",
    "    chapter =state[\"chapters\"][state[\"current_chapter_index\"]]\n",
    "    chapter_title = chapter['title']\n",
    "    chapter_detail = _format_chapters([chapter])\n",
    "    \n",
    "    message_content = (f\"Write or revise the last chapter draft '{chapter_title}'\"\n",
    "                       f\"using agenda, research and advise from reviewer.\"\n",
    "                       f\"\\n\\n{chapter_detail}\")\n",
    "    human_message = HumanMessage(content=message_content, name=\"user\")\n",
    "\n",
    "    messages = state[\"messages\"] + [human_message]\n",
    "\n",
    "    res = writer.invoke(input={\"messages\": messages})\n",
    "\n",
    "    # Check if 'comment' is in the response\n",
    "    writer_script_content = res['script']\n",
    "    writer_response_comment = res.get('comment', 'No comment provided.')\n",
    "\n",
    "    writer_message_content = (f\"## {chapter_title}\"\n",
    "                              f\"\\n\\n{writer_script_content}\\n\\n-----\"\n",
    "                              f\"\\n\\n# Writer Comment\"\n",
    "                              f\"\\n\\n{writer_response_comment}\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [AIMessage(content=writer_message_content, name=\"writer\")],\n",
    "        },\n",
    "        goto=\"reviewer\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c7e82c-8d62-45b1-9bb6-2a0b07e760cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner_node(state: VideoScriptState) -> VideoScriptState:\n",
    "    \"\"\"\n",
    "    The Host/Producer sets the plan (how many chapters, the overall direction).\n",
    "    In a real scenario, you'd call host_producer_prompt with the user request to produce an agenda.\n",
    "    We'll simulate it here.\n",
    "    \"\"\"\n",
    "    # If not already done, let's define chapters in the conversation or from user input\n",
    "    # Example simulation: The user wants a 3-chapter video, so we store that:\n",
    "    if not state.get(\"chapters\"):\n",
    "\n",
    "        planner_prompt = hub.pull(\"tuto-video-script-planner-prompt\")\n",
    "        message_content = planner_prompt.format()\n",
    "        messages = state[\"messages\"] + [HumanMessage(content=message_content, name=\"user\")]\n",
    "        res = planner.invoke(input={\"messages\": messages})\n",
    "        chapters = res['plan']\n",
    "        state[\"chapters\"] = chapters\n",
    "        formatted_chapters = _format_chapters(chapters)\n",
    "        producer_message = (f\"Here's a suggested agenda for your video.\"\n",
    "                            f\"\\n\\n{formatted_chapters}\")\n",
    "        host_message = HumanMessage(content=producer_message, name=\"host-producer\")\n",
    "        state[\"messages\"].append(host_message)\n",
    "        state[\"next\"] = 'research' # HERE\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee83b0f0-8745-44eb-92cc-f9e56efcff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(VideoScriptState)\n",
    "workflow.add_node(\"planning\", planner_node)\n",
    "workflow.add_node(\"researcher\", researcher_node)\n",
    "workflow.add_node(\"writer\", writer_node)\n",
    "workflow.add_node(\"reviewer\", reviewer_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_node)\n",
    "workflow.add_edge(START, \"planning\")\n",
    "workflow.add_edge(\"planning\", \"supervisor\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "video_script_workflow = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd7291c-ba01-407d-8ef9-6a863ffeeae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(video_script_workflow.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1237bbf2-9e35-4d0d-be01-62fcd51a85ae",
   "metadata": {},
   "source": [
    "Now we are getting some serious stuff. \n",
    "\n",
    "Now that we have a real agentic workflow with agent that take decision to the next action, don't forget to add ```\"recursion_limit\"```to configurable. 99 here is absolutely arbitrary. Adapt it to your needs.\n",
    "\n",
    "Let's test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08081b7a-279d-4c44-aaaf-2dba5136acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\"I'd like a 2-chapter video of 2 minutes of 450 words on 'AI Won't Take Your Jobs. Those Who Use AI Will!'\")\n",
    "\n",
    "config = {\"recursion_limit\": 99, \"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "example_input = {\n",
    "    \"messages\": [(\"human\", prompt)],\n",
    "    \"current_chapter_index\": 0,\n",
    "    \"current_chapter_iteration\": 0,\n",
    "    \"final_script\": \"\"\n",
    "}\n",
    "\n",
    "# Collect all steps from the astream generator\n",
    "steps = [step for step in video_script_workflow.stream(example_input, config=config, stream_mode=\"values\")]\n",
    "\n",
    "# Access the last step\n",
    "last_step = steps[-1]\n",
    "\n",
    "print(f\"Directive: '{prompt}'\")\n",
    "\n",
    "# Print the last message of the last step\n",
    "last_message = last_step[\"messages\"][-1]\n",
    "\n",
    "output = last_message.pretty_repr()\n",
    "print(f\"Result: '{output}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0a4ff5-66d2-4330-a1fe-cfdee21ccef9",
   "metadata": {},
   "source": [
    "#### Note\n",
    "We have add \"current_chapter_index\", \"current_chapter_iteration\" and \"final_script\": \"\" to input to initialise value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc37d38-91e5-46e0-a438-2ade544f9c5b",
   "metadata": {},
   "source": [
    "#### Additional tips:\n",
    "##### Retry Policy\n",
    "\n",
    "**Mistral-3-small** has made impressive progress to handle long conversation. With previous mistral-small, you had to regularly face issue with bad or empty structured output causing random 'KeyError' or 'AttributeError' requiring to recall llm. LangGraph offers the possibility to handle this in your graph by adding a retry policy at node level.\n",
    "\n",
    "For example we add retry policy to our workers:\n",
    "```python\n",
    "workflow.add_node(\"researcher\", researcher_node, retry=RetryPolicy(retry_on=[KeyError, AttributeError], max_attempts=3))\n",
    "workflow.add_node(\"writer\", writer_node, retry=RetryPolicy(retry_on=[KeyError, AttributeError], max_attempts=3))\n",
    "workflow.add_node(\"reviewer\", reviewer_node, retry=RetryPolicy(retry_on=[KeyError, AttributeError], max_attempts=3))\n",
    "```\n",
    "\n",
    "##### Remaining Steps\n",
    "[\"recursion_limit\"](https://langchain-ai.github.io/langgraph/concepts/low_level/#recursion-limit) is usefull to ensure that you don't reach a maximum step in your workflow. But you'll certainly want to [return step before hitting that limits](https://langchain-ai.github.io/langgraph/how-tos/return-when-recursion-limit-hits/?h=remaining#with-returning-state).\n",
    "\n",
    "To handle this case, you will add a remaining_step attribute to your StageGraph and handle it in your supervisor_node:\n",
    "```python\n",
    "from langgraph.managed.is_last_step import RemainingSteps\n",
    "\n",
    "class VideoScriptState(TypedDict):\n",
    "    [...]\n",
    "    remaining_steps: RemainingSteps\n",
    "\n",
    "def supervisor_node(state: VideoScriptState) -> Command[Literal[*members, END]]:\n",
    "    # ...\n",
    "\n",
    "    if state[\"remaining_steps\"] <= MIN_REMAINING_STEP:\n",
    "        return Command(goto=END,...\n",
    "    \n",
    "```\n",
    "LangGraph will increment it automatically for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e783b20d-981a-441d-addb-cf330585eb7e",
   "metadata": {},
   "source": [
    "### Where to go from here?\n",
    "\n",
    "Now, you have practiced the basics of LangGraph to build an agentic workflow. To go further, you can explore more advanced techniques of LangGraph like:\n",
    "\n",
    "- [Human-in-the-loop](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/)\n",
    "- [Streaming](https://langchain-ai.github.io/langgraph/concepts/streaming/) and internal state handling (to display progress to user)\n",
    "- [Persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/)\n",
    "- [Memory Management](https://langchain-ai.github.io/langgraph/concepts/memory/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17e10c2-010e-4b31-bdb8-1e0e89c329e4",
   "metadata": {},
   "source": [
    "### Excercices\n",
    "Some ideas for you to practice:\n",
    "\n",
    "- **Extend research agent** with some RAG capabilities on internet with [tavily search](https://tavily.com/). For example add a [Research team](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/hierarchical_agent_teams/#research-team) You'll practice subgraph and function calling. You can also use Agentic RAG if you want to use internal data. In LangGraph example, the research is done before writing process. Possibility is infinite.\n",
    "\n",
    "- **Add a final 'relecture node'** that will adjust the final script to ensure smooth transitions and avoid redundancy between sections.\n",
    "\n",
    "\n",
    "- **Add [parallel execution](https://langchain-ai.github.io/langgraph/how-tos/map-reduce/) of chapter and [aggregation (reducer)](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) for final_script**. In our example, we let the supervisor manage the concatenation as the execution is serialized. We should let LangGraph do the work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5273dfa0-9e6a-48e1-b709-b59a6abc06bd",
   "metadata": {},
   "source": [
    "In a realistic scenario, you'll complete the prompt of each agent with more precise guideline for style, tone, structure. You can have a look at Video Script agent in my [AI-Agent-Casebook](https://github.com/BittnerPierre/AI-Agent-Casebook/tree/main/app/video_script) on my github.\n",
    "\n",
    "You can of course easily adapt the use case to your needs. **Audio Overview** feature of [NotebookLM](https://notebooklm.google/) is not that far away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec462da7-8f46-41ec-b06a-74089fdf7400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai-agent-casebook)",
   "language": "python",
   "name": "ai-agent-casebook-cacfgz2u-py3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
